#!/usr/bin/env python3
"""
éŸ¦ç‰¹å¡”ç½—ä¸“ç”¨è¯†åˆ«ç³»ç»Ÿ
åŸºäºæ‚¨æä¾›çš„æ ‡å‡†éŸ¦ç‰¹å¡”ç½—78å¼ ç‰Œå›¾ç‰‡ï¼Œå®ç°ç²¾å‡†çš„å¡ç‰Œè¯†åˆ«ã€æ­£é€†ä½åˆ¤æ–­å’Œä½ç½®æ£€æµ‹
"""

import cv2
import numpy as np
import json
import imagehash
from PIL import Image
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import time
import math

class WaiteTarotRecognizer:
    def __init__(self, data_dir: str = "data"):
        self.data_dir = Path(data_dir)
        self.reference_dir = self.data_dir / "waite_reference"
        self.reference_dir.mkdir(exist_ok=True)
        
        # éŸ¦ç‰¹å¡”ç½—78å¼ ç‰Œçš„æ ‡å‡†åˆ—è¡¨
        self.waite_cards = {
            # å¤§é˜¿å¡çº³ (Major Arcana) 22å¼ 
            "major": [
                "0æ„šäºº", "1é­”æ³•å¸ˆ", "2å¥³ç¥­å¸", "3çš‡å", "4çš‡å¸", "5æ•™çš‡", "6æ‹äºº", "7æˆ˜è½¦",
                "8åŠ›é‡", "9éšå£«", "10å‘½è¿ä¹‹è½®", "11æ­£ä¹‰", "12å€’åŠäºº", "13æ­»ç¥", "14èŠ‚åˆ¶", 
                "15æ¶é­”", "16é«˜å¡”", "17æ˜Ÿæ˜Ÿ", "18æœˆäº®", "19å¤ªé˜³", "20å®¡åˆ¤", "21ä¸–ç•Œ"
            ],
            # å°é˜¿å¡çº³ (Minor Arcana) 56å¼ 
            "wands": [f"æƒæ–{i}" for i in ["ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "å…­", "ä¸ƒ", "å…«", "ä¹", "å"]] + 
                    ["æƒæ–ä¾ä»", "æƒæ–éª‘å£«", "æƒæ–çš‡å", "æƒæ–å›½ç‹"],
            "cups": [f"åœ£æ¯{i}" for i in ["ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "å…­", "ä¸ƒ", "å…«", "ä¹", "å"]] + 
                   ["åœ£æ¯ä¾ä»", "åœ£æ¯éª‘å£«", "åœ£æ¯çš‡å", "åœ£æ¯å›½ç‹"],
            "swords": [f"å®å‰‘{i}" for i in ["ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "å…­", "ä¸ƒ", "å…«", "ä¹", "å"]] + 
                     ["å®å‰‘ä¾ä»", "å®å‰‘éª‘å£«", "å®å‰‘çš‡å", "å®å‰‘å›½ç‹"],
            "pentacles": [f"æ˜Ÿå¸{i}" for i in ["ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "å…­", "ä¸ƒ", "å…«", "ä¹", "å"]] + 
                         ["æ˜Ÿå¸ä¾ä»", "æ˜Ÿå¸éª‘å£«", "æ˜Ÿå¸çš‡å", "æ˜Ÿå¸å›½ç‹"],
            "attachments":["22ä¾æ‹","23æ¯å­"]
        }
        
        # æ‰€æœ‰78å¼ ç‰Œçš„å®Œæ•´åˆ—è¡¨ï¼ˆæš‚æ—¶ç§»é™¤é™„å±ç‰Œè¿›è¡Œæµ‹è¯•ï¼‰
        self.all_cards = (
            self.waite_cards["major"] + 
            self.waite_cards["wands"] + 
            self.waite_cards["cups"] + 
            self.waite_cards["swords"] + 
            self.waite_cards["pentacles"] +
            self.waite_cards["attachments"]
        )
        
        # å‚è€ƒæ•°æ®åº“
        self.reference_db = {}
        self.load_reference_database()
        
        # å¡ç‰Œæ£€æµ‹å‚æ•°
        self.card_aspect_ratio = 0.67  # éŸ¦ç‰¹å¡”ç½—æ ‡å‡†å®½é«˜æ¯”
        self.min_card_area = 2000  # æœ€å°å¡ç‰Œé¢ç§¯ï¼ˆè¿›ä¸€æ­¥é™ä½ä»¥æ£€æµ‹æ›´å¤šå¡ç‰Œï¼‰
        
    def extract_card_template(self, image_path: str, card_name: str) -> Dict:
        """ä»æ ‡å‡†å¡ç‰Œå›¾ç‰‡æå–æ¨¡æ¿ç‰¹å¾"""
        image = cv2.imread(image_path)
        if image is None:
            return None
        
        # é¢„å¤„ç†
        resized = cv2.resize(image, (200, 300))
        gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)
        
        # å¤šç§å“ˆå¸Œå€¼
        pil_img = Image.fromarray(cv2.cvtColor(resized, cv2.COLOR_BGR2RGB))
        hashes = {
            'phash': str(imagehash.phash(pil_img, hash_size=16)),
            'dhash': str(imagehash.dhash(pil_img, hash_size=16)),
            'whash': str(imagehash.whash(pil_img, hash_size=16)),
            'average_hash': str(imagehash.average_hash(pil_img, hash_size=16))
        }
        
        # SIFTç‰¹å¾ç‚¹
        sift = cv2.SIFT_create(nfeatures=500)
        keypoints, descriptors = sift.detectAndCompute(gray, None)
        
        # ORBç‰¹å¾ç‚¹
        orb = cv2.ORB_create(nfeatures=500)
        kp_orb, desc_orb = orb.detectAndCompute(gray, None)
        
        # é¢œè‰²ç›´æ–¹å›¾
        hist_b = cv2.calcHist([resized], [0], None, [64], [0, 256])
        hist_g = cv2.calcHist([resized], [1], None, [64], [0, 256])
        hist_r = cv2.calcHist([resized], [2], None, [64], [0, 256])
        color_hist = np.concatenate([hist_r.flatten(), hist_g.flatten(), hist_b.flatten()])
        
        # è¾¹ç¼˜ç‰¹å¾
        edges = cv2.Canny(gray, 50, 150)
        edge_hist = cv2.calcHist([edges], [0], None, [256], [0, 256])
        
        return {
            'card_name': card_name,
            'hashes': hashes,
            'sift_keypoints': len(keypoints) if keypoints else 0,
            'sift_descriptors': descriptors.tolist() if descriptors is not None else [],
            'orb_keypoints': len(kp_orb) if kp_orb else 0,
            'orb_descriptors': desc_orb.tolist() if desc_orb is not None else [],
            'color_histogram': color_hist.tolist(),
            'edge_histogram': edge_hist.flatten().tolist(),
            'image_path': image_path,
            'created_at': time.strftime("%Y-%m-%d %H:%M:%S")
        }
    
    def detect_card_regions(self, image: np.ndarray) -> List[Dict]:
        """æ£€æµ‹å›¾ç‰‡ä¸­çš„å¡ç‰ŒåŒºåŸŸ"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # é«˜æ–¯æ¨¡ç³Š
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        
        # å¯¹æ¯”åº¦å¢å¼º
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        enhanced = clahe.apply(blurred)
        
        # ä½¿ç”¨ç®€å•é˜ˆå€¼ - æ ¹æ®è°ƒè¯•ç»“æœè¿™ä¸ªæ•ˆæœæœ€å¥½
        _, thresh = cv2.threshold(enhanced, 127, 255, cv2.THRESH_BINARY)
        
        # å½¢æ€å­¦æ“ä½œ
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        cleaned = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
        cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_OPEN, kernel)
        
        # æ‰¾è½®å»“
        contours, _ = cv2.findContours(cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        card_regions = []
        
        for contour in contours:
            area = cv2.contourArea(contour)
            
            # é™ä½æœ€å°é¢ç§¯è¦æ±‚ä»¥æ£€æµ‹æ›´å¤šå¡ç‰Œ
            if area < 2000:
                continue
            
            # è·å–è¾¹ç•Œæ¡†
            x, y, w, h = cv2.boundingRect(contour)
            aspect_ratio = w / h
            
            # æ›´å®½æ¾çš„å®½é«˜æ¯”æ£€æŸ¥
            if 0.3 < aspect_ratio < 1.2:  # å…è®¸æ›´å¤§èŒƒå›´çš„å˜å½¢
                # è·å–æ—‹è½¬è¾¹ç•Œæ¡†ä»¥æ£€æµ‹å€¾æ–œ
                rect = cv2.minAreaRect(contour)
                box = cv2.boxPoints(rect)
                box = np.array(box, dtype=np.int32)
                
                # è®¡ç®—æ—‹è½¬è§’åº¦
                angle = rect[2]
                if rect[1][0] < rect[1][1]:  # width < height
                    angle += 90
                
                card_regions.append({
                    'bbox': (x, y, w, h),
                    'area': area,
                    'aspect_ratio': aspect_ratio,
                    'contour': contour,
                    'rotated_rect': rect,
                    'box_points': box,
                    'angle': angle,
                    'center': (x + w//2, y + h//2)
                })
        
        # æŒ‰é¢ç§¯æ’åºï¼Œå–æœ€å¤§çš„å‡ ä¸ª
        card_regions.sort(key=lambda x: x['area'], reverse=True)
        return card_regions[:15]  # å¢åŠ åˆ°15å¼ ä»¥æ£€æµ‹æ‰€æœ‰13å¼ å¡ç‰Œ
    
    def extract_card_roi(self, image: np.ndarray, region: Dict) -> Tuple[np.ndarray, bool]:
        """æå–å¡ç‰Œæ„Ÿå…´è¶£åŒºåŸŸå¹¶åˆ¤æ–­æ˜¯å¦ä¸ºé€†ä½"""
        x, y, w, h = region['bbox']
        
        # æå–å¡ç‰ŒåŒºåŸŸ
        card_roi = image[y:y+h, x:x+w]
        
        # æ—‹è½¬æ ¡æ­£
        angle = region['angle']
        is_upside_down = False
        
        if abs(angle) > 10:  # å¦‚æœå€¾æ–œè¶…è¿‡10åº¦
            center = (w//2, h//2)
            rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
            card_roi = cv2.warpAffine(card_roi, rotation_matrix, (w, h))
        
        # åˆ¤æ–­æ­£é€†ä½ - åŸºäºå›¾åƒç‰¹å¾
        # æ–¹æ³•1: æ£€æŸ¥å¡ç‰Œé¡¶éƒ¨å’Œåº•éƒ¨çš„å¤æ‚åº¦
        top_region = card_roi[:h//3, :]
        bottom_region = card_roi[2*h//3:, :]
        
        top_edges = cv2.Canny(cv2.cvtColor(top_region, cv2.COLOR_BGR2GRAY), 50, 150)
        bottom_edges = cv2.Canny(cv2.cvtColor(bottom_region, cv2.COLOR_BGR2GRAY), 50, 150)
        
        top_complexity = np.sum(top_edges > 0)
        bottom_complexity = np.sum(bottom_edges > 0)
        
        # å¦‚æœåº•éƒ¨æ¯”é¡¶éƒ¨å¤æ‚åº¦é«˜å¾ˆå¤šï¼Œå¯èƒ½æ˜¯é€†ä½
        if bottom_complexity > top_complexity * 1.5:
            is_upside_down = True
            # ç¿»è½¬å›¾åƒ
            card_roi = cv2.rotate(card_roi, cv2.ROTATE_180)
        
        # æ ‡å‡†åŒ–å°ºå¯¸
        card_roi = cv2.resize(card_roi, (200, 300))
        
        return card_roi, is_upside_down
    
    def match_card_to_reference(self, card_roi: np.ndarray) -> Dict:
        """å°†æå–çš„å¡ç‰ŒROIä¸å‚è€ƒæ•°æ®åº“åŒ¹é…"""
        if not self.reference_db:
            return {"error": "å‚è€ƒæ•°æ®åº“ä¸ºç©º"}
        
        # é¢„å¤„ç†ï¼šæ ‡å‡†åŒ–å°ºå¯¸å’Œå¢å¼ºè´¨é‡
        # è°ƒæ•´åˆ°æ ‡å‡†å°ºå¯¸
        card_roi = cv2.resize(card_roi, (200, 300))
        
        # å›¾åƒå¢å¼ºï¼šå»å™ªå’Œé”åŒ–
        card_roi = cv2.bilateralFilter(card_roi, 9, 75, 75)
        
        # è®¡ç®—æŸ¥è¯¢å›¾åƒçš„å¤šç§ç‰¹å¾
        gray = cv2.cvtColor(card_roi, cv2.COLOR_BGR2GRAY)
        
        # 1. é¢œè‰²ç‰¹å¾ - ä¸»è¦ç‰¹å¾
        # HSVé¢œè‰²ç›´æ–¹å›¾
        hsv = cv2.cvtColor(card_roi, cv2.COLOR_BGR2HSV)
        hist_h = cv2.calcHist([hsv], [0], None, [50], [0, 180])
        hist_s = cv2.calcHist([hsv], [1], None, [50], [0, 256])
        hist_v = cv2.calcHist([hsv], [2], None, [50], [0, 256])
        color_features = np.concatenate([hist_h.flatten(), hist_s.flatten(), hist_v.flatten()])
        
        # 2. è¾¹ç¼˜ç‰¹å¾
        edges = cv2.Canny(gray, 50, 150)
        edge_density = np.sum(edges > 0) / edges.size  # è¾¹ç¼˜å¯†åº¦
        
        # 3. çº¹ç†ç‰¹å¾ - ç®€åŒ–çš„LBP
        def simple_texture_feature(img):
            mean_val = np.mean(img)
            std_val = np.std(img)
            return [mean_val, std_val]
        
        texture_features = simple_texture_feature(gray)
        
        # 4. å½¢çŠ¶ç‰¹å¾ - è½®å»“å¤æ‚åº¦
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if contours:
            largest_contour = max(contours, key=cv2.contourArea)
            perimeter = cv2.arcLength(largest_contour, True)
            area = cv2.contourArea(largest_contour)
            circularity = 4 * np.pi * area / (perimeter * perimeter) if perimeter > 0 else 0
        else:
            circularity = 0
        
        # åŒ¹é…æ‰€æœ‰å‚è€ƒå¡ç‰Œ
        matches = []
        
        for card_name, ref_data in self.reference_db.items():
            similarities = []
            
            # é¢œè‰²ç›¸ä¼¼åº¦ (æƒé‡60%)
            if ref_data.get('color_histogram'):
                try:
                    ref_hist = np.array(ref_data['color_histogram'], dtype=np.float32)
                    query_hist = color_features.astype(np.float32)
                    
                    # ç¡®ä¿é•¿åº¦ä¸€è‡´
                    min_len = min(len(ref_hist), len(query_hist))
                    ref_hist = ref_hist[:min_len]
                    query_hist = query_hist[:min_len]
                    
                    # ä½¿ç”¨å·´æ°è·ç¦»
                    color_sim = cv2.compareHist(ref_hist, query_hist, cv2.HISTCMP_BHATTACHARYYA)
                    color_sim = max(0, 1 - color_sim)  # è½¬æ¢ä¸ºç›¸ä¼¼åº¦
                    similarities.append(('color', color_sim, 0.6))
                except Exception as e:
                    similarities.append(('color', 0, 0.6))
            
            # è¾¹ç¼˜ç›¸ä¼¼åº¦ (æƒé‡20%)
            if ref_data.get('edge_histogram'):
                try:
                    ref_edges = np.array(ref_data['edge_histogram'], dtype=np.float32)
                    if 'edge_density' in ref_data:
                        ref_edge_density = ref_data['edge_density']
                        edge_density_sim = 1 - abs(edge_density - ref_edge_density) / max(edge_density, ref_edge_density, 0.1)
                        edge_density_sim = max(0, edge_density_sim)
                        similarities.append(('edge', edge_density_sim, 0.2))
                    else:
                        similarities.append(('edge', 0, 0.2))
                except Exception as e:
                    similarities.append(('edge', 0, 0.2))
            
            # å“ˆå¸Œç›¸ä¼¼åº¦ (æƒé‡20%) - é™ä½æƒé‡
            hash_sim = 0
            hash_count = 0
            pil_img = Image.fromarray(cv2.cvtColor(card_roi, cv2.COLOR_BGR2RGB))
            
            try:
                query_phash = str(imagehash.phash(pil_img, hash_size=8))
                if 'hashes' in ref_data and 'phash_8' in ref_data['hashes']:
                    ref_phash = ref_data['hashes']['phash_8']
                    h1 = int(query_phash, 16)
                    h2 = int(ref_phash, 16)
                    hamming_dist = bin(h1 ^ h2).count('1')
                    hash_sim = 1 - (hamming_dist / 64)  # 8x8 = 64 bits
                    hash_count = 1
            except Exception:
                pass
            
            if hash_count > 0:
                similarities.append(('hash', max(0, hash_sim), 0.2))
            else:
                similarities.append(('hash', 0, 0.2))
            
            # è®¡ç®—åŠ æƒå¹³å‡ç›¸ä¼¼åº¦
            total_weight = sum(weight for _, _, weight in similarities)
            if total_weight > 0:
                final_similarity = sum(sim * weight for _, sim, weight in similarities) / total_weight
            else:
                final_similarity = 0
            
            matches.append({
                'card_name': card_name,
                'similarity': final_similarity,
                'details': {sim_type: sim for sim_type, sim, _ in similarities}
            })
        
        # æ’åºå¹¶è¿”å›æœ€ä½³åŒ¹é…
        matches.sort(key=lambda x: x['similarity'], reverse=True)
        
        best_match = matches[0] if matches else None
        
        # é€‚åº”æ€§é˜ˆå€¼ï¼šæ ¹æ®æœ€ä½³åŒ¹é…çš„ç½®ä¿¡åº¦åŠ¨æ€è°ƒæ•´
        adaptive_threshold = max(0.1, best_match['similarity'] * 0.7) if best_match else 0.1
        
        if best_match and best_match['similarity'] > adaptive_threshold:
            return {
                'matched_card': best_match['card_name'],
                'confidence': best_match['similarity'],
                'success': True,
                'all_matches': matches[:3]
            }
        else:
            return {
                'matched_card': None,
                'confidence': best_match['similarity'] if best_match else 0,
                'success': False,
                'all_matches': matches[:3]
            }
    
    def analyze_spread_image(self, image_path: str) -> Dict:
        """åˆ†æå¡”ç½—ç‰Œæ‘Šçš„å®Œæ•´å›¾ç‰‡"""
        image = cv2.imread(image_path)
        if image is None:
            return {"error": f"æ— æ³•è¯»å–å›¾åƒ: {image_path}"}
        
        print(f"ğŸ” åˆ†æå›¾ç‰‡: {Path(image_path).name}")
        
        # æ£€æµ‹å¡ç‰ŒåŒºåŸŸ
        print("   ğŸ“ æ£€æµ‹å¡ç‰ŒåŒºåŸŸ...")
        card_regions = self.detect_card_regions(image)
        print(f"   å‘ç° {len(card_regions)} ä¸ªå€™é€‰åŒºåŸŸ")
        
        # è¯†åˆ«æ¯å¼ å¡ç‰Œ
        recognized_cards = []
        
        for i, region in enumerate(card_regions, 1):
            print(f"   ğŸ´ åˆ†æç¬¬ {i} å¼ å¡ç‰Œ...")
            
            # æå–å¡ç‰ŒROI
            card_roi, is_upside_down = self.extract_card_roi(image, region)
            
            # åŒ¹é…å¡ç‰Œ
            match_result = self.match_card_to_reference(card_roi)
            
            if match_result['success']:
                card_info = {
                    'card_name': match_result['matched_card'],
                    'confidence': match_result['confidence'],
                    'position': region['center'],
                    'bbox': region['bbox'],
                    'area': region['area'],
                    'is_reversed': is_upside_down,
                    'angle': region['angle']
                }
                recognized_cards.append(card_info)
                
                orientation = "é€†ä½" if is_upside_down else "æ­£ä½"
                print(f"      âœ… {match_result['matched_card']} ({orientation}) - ç½®ä¿¡åº¦: {match_result['confidence']:.3f}")
            else:
                print(f"      âŒ æœªè¯†åˆ« - æœ€é«˜ç½®ä¿¡åº¦: {match_result['confidence']:.3f}")
        
        return {
            'image_path': image_path,
            'total_regions': len(card_regions),
            'recognized_cards': recognized_cards,
            'recognition_count': len(recognized_cards),
            'success_rate': len(recognized_cards) / len(card_regions) if card_regions else 0,
            'analysis_time': time.strftime("%Y-%m-%d %H:%M:%S")
        }
    
    def build_reference_from_standard_deck(self):
        """åŸºäºæ ‡å‡†éŸ¦ç‰¹å¡”ç½—å›¾ç‰‡æ„å»ºå‚è€ƒæ•°æ®åº“"""
        print("ğŸ”§ æ„å»ºéŸ¦ç‰¹å¡”ç½—å‚è€ƒæ•°æ®åº“...")
        
        # è¿™é‡Œæˆ‘ä»¬åˆ›å»ºè™šæ‹Ÿå‚è€ƒæ•°æ®
        # å®é™…ä½¿ç”¨æ—¶ï¼Œæ‚¨éœ€è¦æä¾›78å¼ æ ‡å‡†å¡ç‰Œçš„å•ç‹¬å›¾ç‰‡
        for card_name in self.all_cards:
            if card_name not in self.reference_db:
                # åˆ›å»ºåŸºäºå¡ç‰Œåç§°çš„ç¡®å®šæ€§ç‰¹å¾
                seed = hash(card_name) % 1000000
                np.random.seed(seed)
                
                self.reference_db[card_name] = {
                    'card_name': card_name,
                    'hashes': {
                        'phash': f"{hash(card_name) % 0xFFFFFFFFFFFFFFFF:016x}",
                        'dhash': f"{hash(card_name + '_d') % 0xFFFFFFFFFFFFFFFF:016x}",
                        'whash': f"{hash(card_name + '_w') % 0xFFFFFFFFFFFFFFFF:016x}",
                        'average_hash': f"{hash(card_name + '_a') % 0xFFFFFFFFFFFFFFFF:016x}"
                    },
                    'color_histogram': np.random.rand(192).tolist(),
                    'sift_keypoints': np.random.randint(50, 500),
                    'orb_keypoints': np.random.randint(30, 300),
                    'created_at': time.strftime("%Y-%m-%d %H:%M:%S"),
                    'is_virtual': True  # æ ‡è®°ä¸ºè™šæ‹Ÿæ•°æ®
                }
        
        self.save_reference_database()
        print(f"âœ… å·²åˆ›å»º {len(self.reference_db)} å¼ éŸ¦ç‰¹å¡”ç½—å‚è€ƒå¡ç‰Œ")
    
    def save_reference_database(self):
        """ä¿å­˜å‚è€ƒæ•°æ®åº“"""
        db_file = self.data_dir / "models" / "waite_reference_db.json"
        db_file.parent.mkdir(exist_ok=True)
        
        try:
            with open(db_file, 'w', encoding='utf-8') as f:
                json.dump(self.reference_db, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ å‚è€ƒæ•°æ®åº“å·²ä¿å­˜: {db_file}")
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
    
    def load_reference_database(self):
        """åŠ è½½å‚è€ƒæ•°æ®åº“"""
        # ä¼˜å…ˆåŠ è½½å¢å¼ºæ•°æ®åº“
        enhanced_db_file = self.data_dir / "models" / "enhanced_reference_db.json"
        db_file = self.data_dir / "models" / "waite_reference_db.json"
        
        if enhanced_db_file.exists():
            try:
                with open(enhanced_db_file, 'r', encoding='utf-8') as f:
                    self.reference_db = json.load(f)
                print(f"âœ… å·²åŠ è½½å¢å¼ºéŸ¦ç‰¹å¡”ç½—å‚è€ƒæ•°æ®åº“: {len(self.reference_db)} å¼ å¡ç‰Œ")
                return
            except Exception as e:
                print(f"âŒ åŠ è½½å¢å¼ºæ•°æ®åº“å¤±è´¥: {e}")
        
        if db_file.exists():
            try:
                with open(db_file, 'r', encoding='utf-8') as f:
                    self.reference_db = json.load(f)
                print(f"âœ… å·²åŠ è½½éŸ¦ç‰¹å¡”ç½—å‚è€ƒæ•°æ®åº“: {len(self.reference_db)} å¼ å¡ç‰Œ")
            except Exception as e:
                print(f"âŒ åŠ è½½å¤±è´¥: {e}")
                self.reference_db = {}
        else:
            self.reference_db = {}
    
    def visualize_detection_results(self, image_path: str, results: Dict, save_path: str = None):
        """å¯è§†åŒ–æ£€æµ‹ç»“æœ"""
        image = cv2.imread(image_path)
        if image is None:
            return
        
        # ç»˜åˆ¶æ£€æµ‹ç»“æœ
        for card in results['recognized_cards']:
            x, y, w, h = card['bbox']
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            color = (0, 255, 0) if card['confidence'] > 0.8 else (0, 255, 255)
            cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)
            
            # ç»˜åˆ¶å¡ç‰Œåç§°å’Œç½®ä¿¡åº¦
            label = f"{card['card_name']}"
            if card['is_reversed']:
                label += " (é€†ä½)"
            
            label += f" {card['confidence']:.2f}"
            
            # æ–‡å­—èƒŒæ™¯
            (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
            cv2.rectangle(image, (x, y - text_height - 10), (x + text_width, y), color, -1)
            
            # æ–‡å­—
            cv2.putText(image, label, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
            
            # ç»˜åˆ¶ä¸­å¿ƒç‚¹
            center_x, center_y = card['position']
            cv2.circle(image, (center_x, center_y), 5, (255, 0, 0), -1)
        
        # ä¿å­˜ç»“æœ
        if save_path:
            cv2.imwrite(save_path, image)
            print(f"ğŸ“¸ æ£€æµ‹ç»“æœå·²ä¿å­˜: {save_path}")
        
        return image

    def retrain_from_single_cards(self):
        """ä»å•å¼ å¡ç‰Œå›¾ç‰‡é‡æ–°è®­ç»ƒå‚è€ƒæ•°æ®åº“"""
        print("ğŸ”„ ä»å•å¼ å¡ç‰Œå›¾ç‰‡é‡æ–°è®­ç»ƒéŸ¦ç‰¹å¡”ç½—å‚è€ƒæ•°æ®åº“...")
        
        # å•å¼ å¡ç‰Œå›¾ç‰‡ç›®å½•
        cards_dir = self.data_dir / "card_dataset" / "images" / "rider-waite-tarot"
        
        if not cards_dir.exists():
            print(f"âŒ å•å¼ å¡ç‰Œå›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {cards_dir}")
            return False
        
        # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        image_files = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
            image_files.extend(cards_dir.glob(ext))
            image_files.extend(cards_dir.glob(ext.upper()))
        
        if not image_files:
            print(f"âŒ åœ¨ {cards_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
            return False
        
        print(f"ğŸ“ æ‰¾åˆ° {len(image_files)} å¼ å•å¼ å¡ç‰Œå›¾ç‰‡")
        
        # é‡æ–°æ„å»ºæ•°æ®åº“
        new_db = {}
        successful_cards = 0
        
        for image_path in image_files:
            # ä»æ–‡ä»¶åæå–å¡ç‰Œåç§°ï¼ˆå»æ‰æ‰©å±•åï¼‰
            card_name = image_path.stem
            
            # è¿‡æ»¤æ‰éå¡”ç½—ç‰Œå›¾ç‰‡ï¼Œä½†ä¿ç•™é™„å±ç‰Œ
            if any(keyword in card_name for keyword in ['å¦ˆå¦ˆ', 'å­©å­']) and 'ä¾æ‹' not in card_name:
                print(f"â­ï¸  è·³è¿‡éå¡”ç½—ç‰Œå›¾ç‰‡: {card_name}")
                continue
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ ‡å‡†78å¼ ç‰Œä¹‹ä¸€
            if card_name not in self.all_cards:
                print(f"âš ï¸  æœªçŸ¥å¡ç‰Œåç§°: {card_name}")
                continue
            
            # æå–ç‰¹å¾
            features = self.extract_card_features_from_file(str(image_path), card_name)
            if features:
                new_db[card_name] = features
                successful_cards += 1
                print(f"âœ… æˆåŠŸæå–: {card_name}")
            else:
                print(f"âŒ ç‰¹å¾æå–å¤±è´¥: {card_name}")
        
        # ä¿å­˜æ–°æ•°æ®åº“
        if successful_cards >= 60:  # è‡³å°‘60å¼ å¡ç‰Œ
            self.reference_db = new_db
            self.save_reference_database()
            print(f"âœ… é‡æ–°è®­ç»ƒå®Œæˆ: {successful_cards} å¼ å¡ç‰Œ")
            return True
        else:
            print(f"âŒ é‡æ–°è®­ç»ƒå¤±è´¥: åªæˆåŠŸæå– {successful_cards} å¼ å¡ç‰Œ")
            return False
    
    def extract_card_features_from_file(self, image_path: str, card_name: str) -> Dict:
        """ä»å•å¼ å¡ç‰Œå›¾ç‰‡æ–‡ä»¶æå–ç‰¹å¾"""
        try:
            # è¯»å–å›¾åƒ
            image = cv2.imread(image_path)
            if image is None:
                print(f"âŒ æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
                return None
            
            # è°ƒæ•´å›¾åƒå°ºå¯¸åˆ°æ ‡å‡†å¤§å°
            image = cv2.resize(image, (200, 300))
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # HSVé¢œè‰²ç‰¹å¾ - å®Œæ•´å›¾åƒå’ŒåŒºåŸŸç‰¹å¾
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
            
            # å®Œæ•´å›¾åƒHSVç›´æ–¹å›¾
            hist_h = cv2.calcHist([hsv], [0], None, [50], [0, 180])
            hist_s = cv2.calcHist([hsv], [1], None, [50], [0, 256]) 
            hist_v = cv2.calcHist([hsv], [2], None, [50], [0, 256])
            
            # åŒºåŸŸHSVç›´æ–¹å›¾ (ä¸Šä¸­ä¸‹ä¸‰éƒ¨åˆ†)
            h, w = hsv.shape[:2]
            regions = [
                hsv[0:h//3, :],          # ä¸Šéƒ¨
                hsv[h//3:2*h//3, :],     # ä¸­éƒ¨  
                hsv[2*h//3:h, :]         # ä¸‹éƒ¨
            ]
            
            region_hists = []
            for region in regions:
                r_hist_h = cv2.calcHist([region], [0], None, [30], [0, 180])
                r_hist_s = cv2.calcHist([region], [1], None, [30], [0, 256])
                r_hist_v = cv2.calcHist([region], [2], None, [30], [0, 256])
                region_hists.extend([r_hist_h.flatten(), r_hist_s.flatten(), r_hist_v.flatten()])
            
            # ç»„åˆé¢œè‰²ç‰¹å¾
            color_hist = np.concatenate([
                hist_h.flatten(), hist_s.flatten(), hist_v.flatten()
            ] + region_hists)
            
            # å“ˆå¸Œç‰¹å¾ - å¤šç§å°ºå¯¸
            pil_img = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            hashes = {
                'phash_8': str(imagehash.phash(pil_img, hash_size=8)),
                'phash_16': str(imagehash.phash(pil_img, hash_size=16)),
                'dhash_8': str(imagehash.dhash(pil_img, hash_size=8)),
                'average_8': str(imagehash.average_hash(pil_img, hash_size=8))
            }
            
            # è¾¹ç¼˜ç‰¹å¾
            edges = cv2.Canny(gray, 50, 150)
            edge_hist = cv2.calcHist([edges], [0], None, [64], [0, 256])
            edge_density = np.sum(edges > 0) / (edges.shape[0] * edges.shape[1])
            
            # ç®€åŒ–çš„LBPçº¹ç†ç‰¹å¾
            lbp_features = self.extract_simple_lbp(gray)
            
            # å½¢çŠ¶ç‰¹å¾ - åŸºäºè¾¹ç¼˜è½®å»“
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            shape_circularity = 0
            if contours:
                largest_contour = max(contours, key=cv2.contourArea)
                area = cv2.contourArea(largest_contour)
                perimeter = cv2.arcLength(largest_contour, True)
                if perimeter > 0:
                    shape_circularity = 4 * np.pi * area / (perimeter * perimeter)
            
            return {
                'card_name': card_name,
                'hashes': hashes,
                'color_histogram': [float(x) for x in color_hist],
                'edge_histogram': [float(x) for x in edge_hist.flatten()],
                'edge_density': float(edge_density),
                'lbp_features': [float(x) for x in lbp_features],
                'shape_circularity': float(shape_circularity),
                'image_path': image_path,
                'is_enhanced': True,
                'created_at': time.strftime("%Y-%m-%d %H:%M:%S")
            }
            
        except Exception as e:
            print(f"âŒ æå– {card_name} ç‰¹å¾å¤±è´¥: {e}")
            return None
    
    def extract_simple_lbp(self, gray_image: np.ndarray) -> np.ndarray:
        """æå–ç®€åŒ–çš„LBP (Local Binary Pattern) ç‰¹å¾"""
        try:
            # ç®€å•çš„LBPå®ç°
            rows, cols = gray_image.shape
            lbp = np.zeros((rows-2, cols-2), dtype=np.uint8)
            
            for i in range(1, rows-1):
                for j in range(1, cols-1):
                    center = gray_image[i, j]
                    binary_string = ''
                    
                    # 8é‚»åŸŸ
                    neighbors = [
                        gray_image[i-1, j-1], gray_image[i-1, j], gray_image[i-1, j+1],
                        gray_image[i, j+1], gray_image[i+1, j+1], gray_image[i+1, j],
                        gray_image[i+1, j-1], gray_image[i, j-1]
                    ]
                    
                    for neighbor in neighbors:
                        binary_string += '1' if neighbor >= center else '0'
                    
                    lbp[i-1, j-1] = int(binary_string, 2)
            
            # è®¡ç®—LBPç›´æ–¹å›¾
            hist, _ = np.histogram(lbp.ravel(), bins=256, range=(0, 256))
            
            # å½’ä¸€åŒ–
            hist = hist.astype(float)
            hist /= (hist.sum() + 1e-7)
            
            return hist
            
        except Exception as e:
            print(f"LBPç‰¹å¾æå–å¤±è´¥: {e}")
            return np.zeros(256)

    def retrain_from_grid_images(self):
        """ä»ç½‘æ ¼å›¾ç‰‡é‡æ–°è®­ç»ƒå‚è€ƒæ•°æ®åº“ï¼ˆä¿ç•™ä½œä¸ºå¤‡ç”¨æ–¹æ³•ï¼‰"""
        print("ğŸ”„ é‡æ–°è®­ç»ƒéŸ¦ç‰¹å¡”ç½—å‚è€ƒæ•°æ®åº“...")
        
        # å®Œæ•´çš„78å¼ ç‰Œåˆ—è¡¨
        major_cards = [
            "0æ„šäºº", "1é­”æ³•å¸ˆ", "2å¥³ç¥­å¸", "3çš‡å", "4çš‡å¸", "5æ•™çš‡", "6æ‹äºº", "7æˆ˜è½¦",
            "8åŠ›é‡", "9éšå£«", "10å‘½è¿ä¹‹è½®", "11æ­£ä¹‰", "12å€’åŠäºº", "13æ­»ç¥", "14èŠ‚åˆ¶", 
            "15æ¶é­”", "16é«˜å¡”", "17æ˜Ÿæ˜Ÿ", "18æœˆäº®", "19å¤ªé˜³", "20å®¡åˆ¤", "21ä¸–ç•Œ"
        ]
        
        minor_cards = []
        for suit, name in [("æƒæ–", "wands"), ("åœ£æ¯", "cups"), ("å®å‰‘", "swords"), ("æ˜Ÿå¸", "pentacles")]:
            minor_cards.extend([f"{suit}{i}" for i in ["ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "å…­", "ä¸ƒ", "å…«", "ä¹", "å"]])
            minor_cards.extend([f"{suit}ä¾ä»", f"{suit}éª‘å£«", f"{suit}çš‡å", f"{suit}å›½ç‹"])
        
        # æå–å¡ç‰Œçš„å‡½æ•°
        def extract_from_grid(image_path, card_list, rows, cols):
            image = cv2.imread(image_path)
            if image is None:
                return []
            
            h, w = image.shape[:2]
            cell_w, cell_h = w // cols, h // rows
            extracted = []
            
            for i, card_name in enumerate(card_list):
                if i >= rows * cols:
                    break
                row, col = i // cols, i % cols
                x, y = col * cell_w + 10, row * cell_h + 10
                w_crop, h_crop = cell_w - 20, cell_h - 20
                
                card_img = image[y:y+h_crop, x:x+w_crop]
                if card_img.size > 0:
                    card_img = cv2.resize(card_img, (200, 300))
                    features = self.extract_card_template_from_image(card_img, card_name)
                    if features:
                        extracted.append((card_name, features))
            
            return extracted
        
        # é‡æ–°æ„å»ºæ•°æ®åº“
        new_db = {}
        
        # å¤„ç†å¤§é˜¿å¡çº³
        major_path = self.data_dir / "card_images" / "a6afac366671d6e3f755b90bb61c8a7a.jpg"
        if major_path.exists():
            major_data = extract_from_grid(str(major_path), major_cards, 2, 11)
            for card_name, features in major_data:
                new_db[card_name] = features
        
        # å¤„ç†å°é˜¿å¡çº³
        minor_path = self.data_dir / "card_images" / "0cacadb1b61bc63a23f7136ad421ca00.jpg"
        if minor_path.exists():
            minor_data = extract_from_grid(str(minor_path), minor_cards, 4, 14)
            for card_name, features in minor_data:
                new_db[card_name] = features
        
        # ä¿å­˜æ–°æ•°æ®åº“
        if len(new_db) >= 60:  # è‡³å°‘60å¼ å¡ç‰Œ
            self.reference_db = new_db
            self.save_reference_database()
            print(f"âœ… é‡æ–°è®­ç»ƒå®Œæˆ: {len(new_db)} å¼ å¡ç‰Œ")
            return True
        else:
            print(f"âŒ é‡æ–°è®­ç»ƒå¤±è´¥: åªæå–åˆ° {len(new_db)} å¼ å¡ç‰Œ")
            return False
    
    def extract_card_template_from_image(self, image: np.ndarray, card_name: str) -> Dict:
        """ä»å›¾åƒç›´æ¥æå–å¡ç‰Œç‰¹å¾æ¨¡æ¿"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # HSVé¢œè‰²ç‰¹å¾
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
            hist_h = cv2.calcHist([hsv], [0], None, [50], [0, 180])
            hist_s = cv2.calcHist([hsv], [1], None, [50], [0, 256])
            hist_v = cv2.calcHist([hsv], [2], None, [50], [0, 256])
            color_hist = np.concatenate([hist_h.flatten(), hist_s.flatten(), hist_v.flatten()])
            
            # å“ˆå¸Œç‰¹å¾
            pil_img = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            hashes = {
                'phash_8': str(imagehash.phash(pil_img, hash_size=8)),
                'phash_16': str(imagehash.phash(pil_img, hash_size=16))
            }
            
            # è¾¹ç¼˜ç‰¹å¾
            edges = cv2.Canny(gray, 50, 150)
            edge_hist = cv2.calcHist([edges], [0], None, [64], [0, 256])
            
            return {
                'card_name': card_name,
                'hashes': hashes,
                'color_histogram': [float(x) for x in color_hist],
                'edge_histogram': [float(x) for x in edge_hist.flatten()],
                'is_enhanced': True,
                'created_at': time.strftime("%Y-%m-%d %H:%M:%S")
            }
        except Exception as e:
            print(f"âŒ æå– {card_name} ç‰¹å¾å¤±è´¥: {e}")
            return None


def retrain_database():
    """é‡æ–°è®­ç»ƒæ•°æ®åº“çš„ç‹¬ç«‹å‡½æ•°"""
    recognizer = WaiteTarotRecognizer()
    return recognizer.retrain_from_single_cards()


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ´ éŸ¦ç‰¹å¡”ç½—ä¸“ç”¨è¯†åˆ«ç³»ç»Ÿ")
    print("=" * 60)
    
    recognizer = WaiteTarotRecognizer()
    
    # å¦‚æœæ•°æ®åº“ä¸ºç©ºæˆ–å¡ç‰Œæ•°é‡ä¸è¶³ï¼Œé‡æ–°è®­ç»ƒ
    if len(recognizer.reference_db) < 60:
        print("ğŸ“š å‚è€ƒæ•°æ®åº“ä¸è¶³ï¼Œå¼€å§‹é‡æ–°è®­ç»ƒ...")
        recognizer.retrain_from_single_cards()
    
    # æµ‹è¯•è¯†åˆ«
    card_images_dir = Path("data/card_images")
    if card_images_dir.exists():
        # è·å–å¡”ç½—ç‰Œæ‘Šå›¾ç‰‡
        spread_images = [f for f in card_images_dir.glob("*spread*.jpg")] + \
                       [f for f in card_images_dir.glob("*spread*.png")]
        
        if spread_images:
            print(f"\nğŸ§ª æµ‹è¯•å¡”ç½—ç‰Œæ‘Šè¯†åˆ« (å…±{len(spread_images)}å¼ ):")
            
            for spread_img in spread_images:
                print(f"\n{'='*50}")
                results = recognizer.analyze_spread_image(str(spread_img))
                
                if 'error' not in results:
                    print(f"\nğŸ“Š è¯†åˆ«ç»“æœ:")
                    print(f"   æ£€æµ‹åŒºåŸŸ: {results['total_regions']}")
                    print(f"   æˆåŠŸè¯†åˆ«: {results['recognition_count']}")
                    print(f"   æˆåŠŸç‡: {results['success_rate']:.1%}")
                    
                    if results['recognized_cards']:
                        print(f"\nğŸ´ è¯†åˆ«çš„å¡ç‰Œ:")
                        for i, card in enumerate(results['recognized_cards'], 1):
                            orientation = "é€†ä½" if card['is_reversed'] else "æ­£ä½"
                            print(f"   {i}. {card['card_name']} ({orientation}) - ç½®ä¿¡åº¦: {card['confidence']:.3f}")
                
                else:
                    print(f"âŒ {results['error']}")
        else:
            print("ğŸ“· æœªæ‰¾åˆ°å¡”ç½—ç‰Œæ‘Šå›¾ç‰‡ (æ–‡ä»¶ååŒ…å«'spread')")
    
    print(f"\nğŸ“ˆ ç³»ç»ŸçŠ¶æ€:")
    print(f"   éŸ¦ç‰¹å¡”ç½—å¡ç‰Œ: {len(recognizer.all_cards)} å¼ ")
    print(f"   å‚è€ƒæ•°æ®åº“: {len(recognizer.reference_db)} å¼ ")
    print(f"   æ”¯æŒåŠŸèƒ½: å¡ç‰Œè¯†åˆ«ã€æ­£é€†ä½åˆ¤æ–­ã€ä½ç½®æ£€æµ‹")

if __name__ == "__main__":
    main() 