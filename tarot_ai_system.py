#!/usr/bin/env python3
"""
å¡”ç½—AIç³»ç»Ÿ
æ•´åˆå¡ç‰Œè¯†åˆ«ã€RAGæ£€ç´¢å’Œæœ¬åœ°LLMï¼Œæä¾›å®Œæ•´çš„AIè§£ç‰ŒæœåŠ¡
"""

import json
import requests
import base64
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from rag_system import TarotRAGSystem
import time

class TarotAISystem:
    def __init__(self, 
                 llm_model: str = "qwen2.5:1.5b",
                 ollama_url: str = "http://localhost:11434"):
        
        self.llm_model = llm_model
        self.ollama_url = ollama_url
        
        print("ğŸ”® åˆå§‹åŒ–å¡”ç½—AIç³»ç»Ÿ...")
        
        # åˆå§‹åŒ–RAGç³»ç»Ÿ
        print("ğŸ“š åŠ è½½çŸ¥è¯†åº“...")
        self.rag = TarotRAGSystem()
        
        # æµ‹è¯•Ollamaè¿æ¥
        self._test_llm_connection()
        
        print("âœ… å¡”ç½—AIç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
    
    def _test_llm_connection(self):
        """æµ‹è¯•LLMè¿æ¥"""
        try:
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=5)
            if response.status_code == 200:
                models = response.json().get('models', [])
                available_models = [m['name'] for m in models]
                
                if self.llm_model in available_models:
                    print(f"âœ… LLMæ¨¡å‹å¯ç”¨: {self.llm_model}")
                else:
                    print(f"âš ï¸  æ¨¡å‹ {self.llm_model} æœªæ‰¾åˆ°")
                    print(f"å¯ç”¨æ¨¡å‹: {available_models}")
            else:
                print(f"âŒ OllamaæœåŠ¡è¿æ¥å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
        except Exception as e:
            print(f"âŒ Ollamaè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            print("è¯·ç¡®ä¿OllamaæœåŠ¡å·²å¯åŠ¨: ollama serve")
    
    def _call_llm(self, prompt: str, system_prompt: str = None) -> str:
        """è°ƒç”¨æœ¬åœ°LLM"""
        try:
            payload = {
                "model": self.llm_model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "top_p": 0.9,
                    "max_tokens": 2000
                }
            }
            
            if system_prompt:
                payload["system"] = system_prompt
            
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                return result.get('response', '').strip()
            else:
                return f"LLMè°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}"
                
        except Exception as e:
            return f"LLMè°ƒç”¨å‡ºé”™: {e}"
    
    def identify_cards_from_text(self, card_text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­è¯†åˆ«å¡ç‰Œï¼ˆä¸´æ—¶æ–¹æ¡ˆï¼Œæœªæ¥æ›¿æ¢ä¸ºè§†è§‰è¯†åˆ«ï¼‰"""
        # è¯»å–å·²çŸ¥å¡ç‰Œåˆ—è¡¨
        card_list_file = Path("data/processed/all_cards/card_list.json")
        if card_list_file.exists():
            with open(card_list_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                all_cards = data.get('all_cards', [])
        else:
            all_cards = []
        
        # ç®€å•çš„å¡ç‰Œè¯†åˆ«é€»è¾‘
        identified_cards = []
        for card in all_cards:
            if card in card_text:
                identified_cards.append(card)
        
        return identified_cards
    
    def generate_reading(self, 
                        cards: List[str], 
                        question: str = None,
                        user_id: str = None,
                        spread_type: str = "general") -> Dict:
        """ç”Ÿæˆå¡”ç½—è§£ç‰Œ"""
        
        print(f"ğŸ´ å¼€å§‹è§£ç‰Œ...")
        print(f"å¡ç‰Œ: {cards}")
        print(f"é—®é¢˜: {question}")
        
        # 1. ç”ŸæˆæŸ¥è¯¢æ–‡æœ¬
        if question:
            query = f"{question} {' '.join(cards)}"
        else:
            query = f"å¡”ç½—è§£ç‰Œ {' '.join(cards)}"
        
        # 2. ä½¿ç”¨RAGè·å–ç›¸å…³ä¸Šä¸‹æ–‡
        print("ğŸ” æ£€ç´¢ç›¸å…³çŸ¥è¯†...")
        context = self.rag.generate_context_for_query(query, user_id)
        
        # 3. æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¡”ç½—å åœå¸ˆï¼Œæ‹¥æœ‰æ·±åšçš„å¡”ç½—ç‰Œè§£è¯»èƒ½åŠ›ã€‚
ä½ çš„è§£ç‰Œé£æ ¼ç‰¹ç‚¹ï¼š
- æ·±å…¥ç»†è‡´ï¼Œå¯Œæœ‰æ´å¯ŸåŠ›
- ç»“åˆå¿ƒç†å­¦å’Œçµæ€§æ™ºæ…§
- å…³æ³¨å†…åœ¨æˆé•¿å’ŒæŒ‡å¯¼æ„ä¹‰
- è¯­è¨€ä¼˜ç¾ï¼Œå¯Œæœ‰è¯—æ„

è¯·åŸºäºæä¾›çš„å¡ç‰Œå’ŒèƒŒæ™¯çŸ¥è¯†ï¼Œè¿›è¡Œä¸“ä¸šçš„å¡”ç½—è§£è¯»ã€‚
è§£è¯»åº”è¯¥åŒ…å«ï¼š
1. å¡ç‰Œç»„åˆçš„æ•´ä½“èƒ½é‡
2. æ¯å¼ ä¸»è¦å¡ç‰Œçš„å«ä¹‰
3. å¯¹å½“å‰æƒ…å†µçš„æ´å¯Ÿ
4. æœªæ¥çš„å»ºè®®å’ŒæŒ‡å¯¼

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œè¯­æ°”æ¸©å’Œè€Œå……æ»¡æ™ºæ…§ã€‚"""
        
        # 4. æ„å»ºç”¨æˆ·æç¤ºè¯
        user_prompt = f"""è¯·ä¸ºä»¥ä¸‹å¡”ç½—ç‰Œé˜µè¿›è¡Œè§£è¯»ï¼š

å¡ç‰Œï¼š{', '.join(cards)}
é—®é¢˜ï¼š{question if question else 'ç»¼åˆè¿åŠ¿'}
ç‰Œé˜µç±»å‹ï¼š{spread_type}

ç›¸å…³èƒŒæ™¯çŸ¥è¯†ï¼š
{context}

è¯·è¿›è¡Œè¯¦ç»†è€Œæ·±å…¥çš„è§£è¯»ï¼š"""
        
        # 5. è°ƒç”¨LLMç”Ÿæˆè§£è¯»
        print("ğŸ¤– AIæ­£åœ¨è§£ç‰Œ...")
        start_time = time.time()
        reading_text = self._call_llm(user_prompt, system_prompt)
        generation_time = time.time() - start_time
        
        # 6. æ•´ç†ç»“æœ
        result = {
            "cards": cards,
            "question": question,
            "spread_type": spread_type,
            "reading": reading_text,
            "context_used": context[:500] + "..." if len(context) > 500 else context,
            "user_id": user_id,
            "timestamp": time.time(),
            "generation_time": generation_time,
            "model_used": self.llm_model
        }
        
        # 7. ä¿å­˜åˆ°ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœæœ‰ç”¨æˆ·IDï¼‰
        if user_id:
            self.rag.add_user_context(user_id, {
                "type": "reading",
                "summary": f"è§£è¯»äº† {', '.join(cards[:3])} ç­‰å¡ç‰Œ",
                "cards": cards,
                "themes": [question] if question else ["ç»¼åˆè¿åŠ¿"],
                "notes": f"ç”Ÿæˆæ—¶é—´: {generation_time:.2f}ç§’"
            })
        
        print(f"âœ… è§£ç‰Œå®Œæˆ (ç”¨æ—¶ {generation_time:.2f}ç§’)")
        return result
    
    def analyze_image(self, image_path: str) -> List[str]:
        """åˆ†æå›¾ç‰‡ä¸­çš„å¡ç‰Œï¼ˆå ä½å‡½æ•°ï¼‰"""
        print(f"ğŸ“¸ åˆ†æå›¾ç‰‡: {image_path}")
        
        # TODO: è¿™é‡Œå°†æ¥æ•´åˆè§†è§‰è¯†åˆ«æ¨¡å‹
        # ç›®å‰è¿”å›ä¸€äº›ç¤ºä¾‹å¡ç‰Œ
        sample_cards = ["åŠ›é‡", "é­”æ³•å¸ˆ", "çš‡å"]
        
        print(f"è¯†åˆ«åˆ°å¡ç‰Œ: {sample_cards}")
        return sample_cards
    
    def interactive_reading(self):
        """äº¤äº’å¼è§£ç‰Œ"""
        print("\nğŸ”® æ¬¢è¿ä½¿ç”¨å¡”ç½—AIè§£ç‰Œç³»ç»Ÿ")
        print("=" * 50)
        
        while True:
            print("\né€‰æ‹©è¾“å…¥æ–¹å¼ï¼š")
            print("1. æ‰‹åŠ¨è¾“å…¥å¡ç‰Œ")
            print("2. åˆ†æå›¾ç‰‡ (æš‚æœªå®ç°)")
            print("3. é€€å‡º")
            
            choice = input("\nè¯·é€‰æ‹© (1-3): ").strip()
            
            if choice == "1":
                self._manual_card_input()
            elif choice == "2":
                print("ğŸ“¸ å›¾ç‰‡åˆ†æåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­...")
                self._image_analysis_demo()
            elif choice == "3":
                print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨å¡”ç½—AIç³»ç»Ÿï¼")
                break
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
    
    def _manual_card_input(self):
        """æ‰‹åŠ¨è¾“å…¥å¡ç‰Œ"""
        print("\nğŸ´ æ‰‹åŠ¨è¾“å…¥å¡ç‰Œ")
        print("è¯·è¾“å…¥å¡ç‰Œåç§°ï¼Œç”¨é€—å·åˆ†éš” (ä¾‹å¦‚: æ„šè€…,é­”æ³•å¸ˆ,çš‡å)")
        
        card_input = input("å¡ç‰Œ: ").strip()
        if not card_input:
            print("âŒ æœªè¾“å…¥å¡ç‰Œ")
            return
        
        cards = [card.strip() for card in card_input.split(',') if card.strip()]
        
        question = input("é—®é¢˜ (å¯é€‰): ").strip()
        user_id = input("ç”¨æˆ·ID (å¯é€‰): ").strip()
        
        if not user_id:
            user_id = "anonymous"
        
        # ç”Ÿæˆè§£è¯»
        result = self.generate_reading(cards, question, user_id)
        
        # æ˜¾ç¤ºç»“æœ
        self._display_reading_result(result)
    
    def _image_analysis_demo(self):
        """å›¾ç‰‡åˆ†ææ¼”ç¤º"""
        print("\nğŸ“¸ å›¾ç‰‡åˆ†ææ¼”ç¤º")
        
        image_path = input("è¯·è¾“å…¥å›¾ç‰‡è·¯å¾„: ").strip()
        if not image_path or not Path(image_path).exists():
            print("âŒ å›¾ç‰‡è·¯å¾„æ— æ•ˆ")
            return
        
        # æ¨¡æ‹Ÿå¡ç‰Œè¯†åˆ«
        cards = self.analyze_image(image_path)
        
        question = input("é—®é¢˜ (å¯é€‰): ").strip()
        user_id = input("ç”¨æˆ·ID (å¯é€‰): ").strip()
        
        if not user_id:
            user_id = "anonymous"
        
        # ç”Ÿæˆè§£è¯»
        result = self.generate_reading(cards, question, user_id)
        
        # æ˜¾ç¤ºç»“æœ
        self._display_reading_result(result)
    
    def _display_reading_result(self, result: Dict):
        """æ˜¾ç¤ºè§£è¯»ç»“æœ"""
        print("\n" + "="*60)
        print("ğŸ”® å¡”ç½—è§£è¯»ç»“æœ")
        print("="*60)
        
        print(f"\nğŸ´ å¡ç‰Œ: {', '.join(result['cards'])}")
        if result['question']:
            print(f"â“ é—®é¢˜: {result['question']}")
        print(f"ğŸ• ç”Ÿæˆæ—¶é—´: {result['generation_time']:.2f}ç§’")
        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {result['model_used']}")
        
        print(f"\nğŸ“– è§£è¯»:")
        print("-" * 40)
        print(result['reading'])
        print("-" * 40)
        
        # è¯¢é—®æ˜¯å¦ä¿å­˜
        save = input("\nğŸ’¾ æ˜¯å¦ä¿å­˜æ­¤æ¬¡è§£è¯»ï¼Ÿ(y/n): ").strip().lower()
        if save == 'y':
            self._save_reading(result)
    
    def _save_reading(self, result: Dict):
        """ä¿å­˜è§£è¯»ç»“æœ"""
        readings_dir = Path("data/ai_readings")
        readings_dir.mkdir(exist_ok=True)
        
        timestamp = int(result['timestamp'])
        filename = f"reading_{timestamp}.json"
        filepath = readings_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… è§£è¯»å·²ä¿å­˜: {filepath}")
    
    def get_system_stats(self) -> Dict:
        """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        rag_stats = self.rag.get_database_stats()
        
        # æ£€æŸ¥AIè§£è¯»æ•°é‡
        ai_readings_dir = Path("data/ai_readings")
        ai_readings_count = len(list(ai_readings_dir.glob("*.json"))) if ai_readings_dir.exists() else 0
        
        return {
            "knowledge_base": rag_stats,
            "ai_readings": ai_readings_count,
            "llm_model": self.llm_model
        }

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŸ å¡”ç½—AIç³»ç»Ÿå¯åŠ¨")
    
    try:
        # åˆå§‹åŒ–ç³»ç»Ÿ
        tarot_ai = TarotAISystem()
        
        # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
        print("\nğŸ“Š ç³»ç»ŸçŠ¶æ€:")
        stats = tarot_ai.get_system_stats()
        print(f"çŸ¥è¯†åº“: {stats['knowledge_base']}")
        print(f"AIè§£è¯»è®°å½•: {stats['ai_readings']} æ¡")
        print(f"LLMæ¨¡å‹: {stats['llm_model']}")
        
        # å¼€å§‹äº¤äº’
        tarot_ai.interactive_reading()
        
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {e}")
        print("è¯·æ£€æŸ¥ï¼š")
        print("1. OllamaæœåŠ¡æ˜¯å¦å¯åŠ¨: ollama serve")
        print("2. æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½: ollama pull qwen2.5:1.5b")
        print("3. RAGç³»ç»Ÿæ˜¯å¦å·²åˆå§‹åŒ–")

if __name__ == "__main__":
    main() 