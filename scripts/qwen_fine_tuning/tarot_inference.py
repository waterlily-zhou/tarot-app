#!/usr/bin/env python3
"""
ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹è¿›è¡Œå¡”ç½—è§£è¯»
"""

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel

class TarotAI:
    def __init__(self, model_path="./qwen_tarot_lora"):
        print("ğŸ”® åŠ è½½å¡”ç½—AIæ¨¡å‹...")
        
        self.tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
        
        # åŠ è½½LoRAæ¨¡å‹
        base_model = AutoModelForCausalLM.from_pretrained(
            "Qwen/Qwen1.5-7B-Chat",
            torch_dtype=torch.bfloat16,
            device_map="auto",
            trust_remote_code=True
        )
        self.model = PeftModel.from_pretrained(base_model, model_path)
        
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    
    def generate_reading(self, person: str, question: str, cards: list, spread: str = "è‡ªå®šä¹‰") -> str:
        """ç”Ÿæˆå¡”ç½—è§£è¯»"""
        cards_str = "ï¼›".join(cards)
        
        prompt = f"""è¯·ä¸ºä»¥ä¸‹å¡”ç½—ç‰Œè§£è¯»æä¾›ä¸“ä¸šåˆ†æï¼š

å’¨è¯¢è€…ï¼š{person}
é—®é¢˜ï¼š{question}
ç‰Œé˜µï¼š{spread}
æŠ½åˆ°çš„ç‰Œï¼š{cards_str}

è¯·æä¾›æ·±å…¥çš„è§£è¯»ï¼ŒåŒ…æ‹¬ï¼š
1. æ¯å¼ ç‰Œçš„å«ä¹‰å’Œåœ¨æ­¤æƒ…å¢ƒä¸‹çš„è§£é‡Š
2. ç‰Œä¸ç‰Œä¹‹é—´çš„å…³ç³»å’Œèƒ½é‡æµåŠ¨
3. æ•´ä½“çš„æŒ‡å¯¼å»ºè®®å’Œæ´å¯Ÿ
4. å’¨è¯¢è€…å½“å‰çš„èƒ½é‡çŠ¶æ€å’Œå‘å±•æ–¹å‘"""

        messages = [{"role": "user", "content": prompt}]
        text = self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
        
        inputs = self.tokenizer([text], return_tensors="pt").to(self.model.device)
        
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=2048,
                temperature=0.7,
                top_p=0.9,
                do_sample=True,
                pad_token_id=self.tokenizer.eos_token_id
            )
        
        response = self.tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)
        return response.strip()

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    ai = TarotAI()
    
    reading = ai.generate_reading(
        person="æµ‹è¯•ç”¨æˆ·",
        question="èŒä¸šå‘å±•æ–¹å‘",
        cards=["æ„šäºº", "é­”æ³•å¸ˆ(æ­£ä½)", "å¥³ç¥­å¸(é€†ä½)", "çš‡å"],
        spread="å››å…ƒç´ ç‰Œé˜µ"
    )
    
    print(reading) 