#!/bin/bash
# Lambdaè®­ç»ƒç¯å¢ƒè®¾ç½®è„šæœ¬
set -e

echo "ğŸš€ å¼€å§‹è®¾ç½®Lambdaè®­ç»ƒç¯å¢ƒ"
echo "================================"

echo "ğŸ“‹ 1. æ£€æŸ¥ä¸Šä¼ çš„æ–‡ä»¶..."
ls -la ~/

echo "ğŸ”“ 2. è§£å¯†è®­ç»ƒæ•°æ®..."
python3 privacy_encryption.py --decrypt training_data.jsonl.encrypted

echo "ğŸ“¦ 3. å®‰è£…ä¾èµ–åŒ…..."
pip install transformers datasets accelerate bitsandbytes torch

echo "ğŸŒ 4. ä¸‹è½½DeepSeek R1æ¨¡å‹ï¼ˆä¸´æ—¶å¯ç”¨ç½‘ç»œï¼‰..."
# ä¸´æ—¶ç¦ç”¨ç¦»çº¿æ¨¡å¼
unset HF_HUB_OFFLINE TRANSFORMERS_OFFLINE WANDB_DISABLED

echo "ä¸‹è½½tokenizer..."
python3 -c "
from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained('deepseek-ai/DeepSeek-R1-0528')
print('âœ… Tokenizerä¸‹è½½å®Œæˆ')
"

echo "ä¸‹è½½æ¨¡å‹..."
python3 -c "
from transformers import AutoModelForCausalLM
import torch
model = AutoModelForCausalLM.from_pretrained(
    'deepseek-ai/DeepSeek-R1-0528',
    torch_dtype=torch.float16,
    device_map='auto',
    trust_remote_code=True
)
print('âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ')
"

echo "ğŸ›¡ï¸ 5. å¯ç”¨éšç§ä¿æŠ¤ç¯å¢ƒ..."
source private_env.sh

echo "ğŸ¯ 6. å¯åŠ¨è®­ç»ƒ..."
python3 private_train.py

echo "âœ… Lambdaè®­ç»ƒç¯å¢ƒè®¾ç½®å®Œæˆï¼" 