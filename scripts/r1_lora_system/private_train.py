#!/usr/bin/env python3
"""
éšç§ä¿æŠ¤è®­ç»ƒè„šæœ¬ - LambdaæœåŠ¡å™¨ç‰ˆ (ä¼˜åŒ–ç‰ˆ)
ğŸ”’ ä¼˜åŒ–æ˜¾å­˜ä½¿ç”¨çš„éšç§ä¿æŠ¤è®­ç»ƒ
"""
import os
import sys
import subprocess

def setup_private_environment():
    """è®¾ç½®éšç§ä¿æŠ¤ç¯å¢ƒ"""
    print("ğŸ“¦ æ¿€æ´»ä¼˜åŒ–çš„éšç§ä¿æŠ¤æ¨¡å¼...")
    
    # ğŸš€ æ˜¾å­˜ä¼˜åŒ–ç¯å¢ƒå˜é‡
    os.environ["PYTHONUNBUFFERED"] = "1"
    os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "max_split_size_mb:512"
    
    # ç¦ç”¨å¤–éƒ¨æœåŠ¡ (ä½†å…è®¸æ¨¡å‹ä¸‹è½½)
    os.environ["WANDB_DISABLED"] = "true"
    os.environ["TRANSFORMERS_NO_ADVISORY_WARNINGS"] = "1"
    os.environ["TOKENIZERS_PARALLELISM"] = "false"
    
    # æœ¬åœ°æ—¥å¿—
    os.environ["TENSORBOARD_LOG_DIR"] = "./private_logs"
    
    # åˆ›å»ºå¿…è¦ç›®å½•
    os.makedirs("./offload", exist_ok=True)
    os.makedirs("./private_logs", exist_ok=True)
    
    print("âœ… ä¼˜åŒ–çš„éšç§ä¿æŠ¤ç¯å¢ƒå·²æ¿€æ´»")

if __name__ == "__main__":
    # æ¿€æ´»éšç§ä¿æŠ¤
    setup_private_environment()
    
    # ğŸš€ GPUå†…å­˜é¢„æ¸…ç†
    try:
        import torch
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            print("ğŸ§¹ GPUç¼“å­˜å·²æ¸…ç†")
    except ImportError:
        pass
    
    # å¯¼å…¥å¹¶è¿è¡ŒåŸå§‹è®­ç»ƒè„šæœ¬
    print("ğŸ”’ å¼€å§‹ä¼˜åŒ–çš„éšç§ä¿æŠ¤è®­ç»ƒ...")
    
    try:
        from train_70b_qlora import train_70b_qlora
        success = train_70b_qlora()
        
        if success:
            print("ğŸ‰ éšç§ä¿æŠ¤è®­ç»ƒå®Œæˆï¼")
        else:
            print("âŒ è®­ç»ƒå¤±è´¥")
    except ImportError:
        print("âŒ æ— æ³•å¯¼å…¥è®­ç»ƒè„šæœ¬ï¼Œè¯·ç¡®ä¿train_70b_qlora.pyå­˜åœ¨")
    except Exception as e:
        print(f"âŒ è®­ç»ƒå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
