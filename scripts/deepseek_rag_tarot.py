#!/usr/bin/env python3
"""
DeepSeek R1 + RAG å¡”ç½—AIç³»ç»Ÿ - æ€§ä»·æ¯”æœ€ä¼˜æ–¹æ¡ˆ
"""

import os
import json
import sqlite3
from pathlib import Path
from typing import List, Dict
import re

try:
    import openai
    from sentence_transformers import SentenceTransformer
    import numpy as np
    print("âœ… ä¾èµ–åº“å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ ç¼ºå°‘ä¾èµ–åº“: {e}")
    print("è¯·å®‰è£…: pip install openai sentence-transformers")
    exit(1)

class DeepSeekTarotRAG:
    """DeepSeek R1 + RAG å¡”ç½—AIç³»ç»Ÿ"""
    
    def __init__(self):
        self.client = None
        self.embedding_model = None
        self.db_path = "data/deepseek_tarot_knowledge.db"
        self.init_deepseek()
        self.init_database()
        
    def init_deepseek(self):
        """åˆå§‹åŒ–DeepSeekå®¢æˆ·ç«¯"""
        # é¦–å…ˆå°è¯•ä»ç¯å¢ƒå˜é‡è¯»å–
        api_key = os.getenv("DEEPSEEK_API_KEY")
        
        # å¦‚æœç¯å¢ƒå˜é‡æ²¡æœ‰ï¼Œå°è¯•ä» .env.local æ–‡ä»¶è¯»å–
        if not api_key:
            env_file = Path(".env.local")
            if env_file.exists():
                with open(env_file, 'r') as f:
                    for line in f:
                        line = line.strip()
                        if line.startswith("DEEPSEEK_API_KEY="):
                            api_key = line.split("=", 1)[1].strip().strip('"').strip("'")
                            break
        
        if not api_key:
            print("âŒ è¯·è®¾ç½® DEEPSEEK_API_KEY")
            print("æ–¹æ³•1: export DEEPSEEK_API_KEY='your-api-key'")
            print("æ–¹æ³•2: åœ¨ .env.local æ–‡ä»¶ä¸­æ·»åŠ  DEEPSEEK_API_KEY=your-api-key")
            print("ğŸ”— è·å–API Key: https://platform.deepseek.com/api_keys")
            return False
        
        # ä½¿ç”¨DeepSeekçš„APIç«¯ç‚¹
        self.client = openai.OpenAI(
            api_key=api_key,
            base_url="https://api.deepseek.com/v1"
        )
        print("âœ… DeepSeek R1 å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        return True
    
    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS readings (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                person TEXT,
                question TEXT,
                cards TEXT,
                spread TEXT,
                content TEXT,
                embedding BLOB,
                source_file TEXT
            )
        ''')
        
        conn.commit()
        conn.close()
        print(f"âœ… çŸ¥è¯†åº“åˆå§‹åŒ–å®Œæˆ: {self.db_path}")
    
    def load_embedding_model(self):
        """åŠ è½½åµŒå…¥æ¨¡å‹"""
        if self.embedding_model is None:
            print("ğŸ“¥ åŠ è½½åµŒå…¥æ¨¡å‹...")
            self.embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
            print("âœ… åµŒå…¥æ¨¡å‹åŠ è½½æˆåŠŸ")
        return self.embedding_model
    
    def build_knowledge_base(self):
        """æ„å»ºçŸ¥è¯†åº“"""
        print("ğŸ“š æ„å»ºçŸ¥è¯†åº“...")
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('SELECT COUNT(*) FROM readings')
        count = cursor.fetchone()[0]
        conn.close()
        
        if count > 0:
            print(f"âœ… çŸ¥è¯†åº“å·²æœ‰ {count} æ¡è®°å½•")
            return
        
        # ä»è®­ç»ƒæ•°æ®æ„å»ºçŸ¥è¯†åº“
        data_file = "data/finetune/tarot_readings.jsonl"
        if not Path(data_file).exists():
            print(f"âŒ è®­ç»ƒæ•°æ®ä¸å­˜åœ¨: {data_file}")
            return
        
        embedding_model = self.load_embedding_model()
        count = 0
        
        with open(data_file, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    sample = json.loads(line)
                    metadata = sample['metadata']
                    
                    person = metadata.get('person', '')
                    cards = metadata.get('cards', [])
                    spread = metadata.get('spread', '')
                    content = sample['response']
                    source_file = metadata.get('source_file', '')
                    
                    # ä»æŒ‡ä»¤ä¸­æå–é—®é¢˜
                    instruction = sample['instruction']
                    question_match = re.search(r'é—®é¢˜ï¼š([^\n]+)', instruction)
                    question = question_match.group(1) if question_match else ''
                    
                    # ç”ŸæˆåµŒå…¥
                    query_text = f"å’¨è¯¢è€…:{person} é—®é¢˜:{question} ç‰Œ:{';'.join(cards)} ç‰Œé˜µ:{spread}"
                    embedding = embedding_model.encode(query_text)
                    
                    # å­˜å‚¨åˆ°æ•°æ®åº“
                    conn = sqlite3.connect(self.db_path)
                    cursor = conn.cursor()
                    
                    cursor.execute('''
                        INSERT INTO readings (person, question, cards, spread, content, embedding, source_file)
                        VALUES (?, ?, ?, ?, ?, ?, ?)
                    ''', (person, question, ';'.join(cards), spread, content, 
                          embedding.tobytes(), source_file))
                    
                    conn.commit()
                    conn.close()
                    
                    count += 1
                    if count % 20 == 0:
                        print(f"   å·²å¤„ç† {count} æ¡è®°å½•...")
                        
                except Exception as e:
                    print(f"âš ï¸ å¤„ç†è®°å½•æ—¶å‡ºé”™: {e}")
        
        print(f"âœ… çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼Œå…± {count} æ¡è®°å½•")
    
    def search_similar_readings(self, person: str, question: str, 
                              cards: List[str], spread: str, top_k: int = 5) -> List[Dict]:
        """æœç´¢ç›¸ä¼¼è§£è¯» - ä¼˜åŒ–ç‰ˆ"""
        embedding_model = self.load_embedding_model()
        
        # ç”ŸæˆæŸ¥è¯¢åµŒå…¥
        query_text = f"å’¨è¯¢è€…:{person} é—®é¢˜:{question} ç‰Œ:{';'.join(cards)} ç‰Œé˜µ:{spread}"
        query_embedding = embedding_model.encode(query_text)
        
        # ä»æ•°æ®åº“æ£€ç´¢
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('SELECT * FROM readings')
        rows = cursor.fetchall()
        conn.close()
        
        if not rows:
            return []
        
        # è®¡ç®—å¢å¼ºç›¸ä¼¼åº¦
        similarities = []
        query_cards_set = set([card.strip().replace('(æ­£ä½)', '').replace('(é€†ä½)', '') 
                              for card in cards])
        
        for row in rows:
            stored_embedding = np.frombuffer(row[6], dtype=np.float32)
            
            # åŸºç¡€è¯­ä¹‰ç›¸ä¼¼åº¦
            semantic_similarity = np.dot(query_embedding, stored_embedding) / (
                np.linalg.norm(query_embedding) * np.linalg.norm(stored_embedding)
            )
            
            # è®¡ç®—ç‰Œç»„é‡å åº¦
            stored_cards = row[3].split(';') if row[3] else []
            stored_cards_set = set([card.strip().replace('(æ­£ä½)', '').replace('(é€†ä½)', '') 
                                   for card in stored_cards])
            
            card_overlap = len(query_cards_set & stored_cards_set)
            total_cards = len(query_cards_set | stored_cards_set)
            card_similarity = card_overlap / max(total_cards, 1) if total_cards > 0 else 0
            
            # åŒå’¨è¯¢è€…åŠ æƒ
            person_bonus = 0.2 if row[1] == person else 0
            
            # åŒç‰Œé˜µç±»å‹åŠ æƒ
            spread_bonus = 0.1 if row[4] == spread else 0
            
            # ç»¼åˆç›¸ä¼¼åº¦è®¡ç®—
            final_similarity = (
                semantic_similarity * 0.5 +  # è¯­ä¹‰ç›¸ä¼¼åº¦æƒé‡50%
                card_similarity * 0.3 +      # ç‰Œç»„ç›¸ä¼¼åº¦æƒé‡30%
                person_bonus +               # åŒäººåŠ æƒ20%
                spread_bonus                 # åŒç‰Œé˜µåŠ æƒ10%
            )
            
            similarities.append({
                'person': row[1],
                'question': row[2],
                'cards': row[3],
                'spread': row[4],
                'content': row[5],
                'source_file': row[7],
                'similarity': final_similarity,
                'semantic_sim': semantic_similarity,
                'card_overlap': card_overlap,
                'card_similarity': card_similarity
            })
        
        # æŒ‰ç»¼åˆç›¸ä¼¼åº¦æ’åº
        similarities.sort(key=lambda x: x['similarity'], reverse=True)
        return similarities[:top_k]
    
    def generate_reading(self, person: str, question: str, 
                        cards: List[str], spread: str = "è‡ªç”±ç‰Œé˜µ") -> str:
        """ç”Ÿæˆè§£è¯»"""
        
        if not self.client:
            return "âŒ DeepSeek å®¢æˆ·ç«¯æœªåˆå§‹åŒ–"
        
        print("ğŸ” æ£€ç´¢ç›¸ä¼¼è§£è¯»...")
        similar_readings = self.search_similar_readings(person, question, cards, spread, top_k=5)
        
        print("ğŸ¤– ä½¿ç”¨ DeepSeek R1 ç”Ÿæˆè§£è¯»...")
        
        # æ„å»ºç³»ç»Ÿæç¤º - é’ˆå¯¹DeepSeek R1ä¼˜åŒ–
        system_prompt = """ä½ æ˜¯ä¸€ä½å…·æœ‰æ·±åšä¸“ä¸šèƒŒæ™¯çš„å¡”ç½—å¸ˆï¼Œæ‹¥æœ‰ä¸°å¯Œçš„å æ˜Ÿå­¦ã€å¿ƒç†å­¦å’Œçµæ€§æ™ºæ…§ã€‚ä½ çš„è§£è¯»é£æ ¼æ·±åˆ»ã€å¯Œæœ‰æ´å¯ŸåŠ›ï¼Œèƒ½å¤Ÿé€šè¿‡å¡”ç½—ç‰Œé€è§†å’¨è¯¢è€…çš„å†…åœ¨ä¸–ç•Œå’Œäººç”Ÿè®®é¢˜ã€‚

ä½ çš„è§£è¯»ç‰¹è‰²ï¼š
1. å¯¹æ¯å¼ ç‰Œè¿›è¡Œæ·±åº¦åˆ†æï¼Œé˜é‡Šå…¶åœ¨å½“å‰æƒ…å¢ƒä¸­çš„æ„ä¹‰
2. æ¢è®¨ç‰Œä¸ç‰Œä¹‹é—´çš„å…³ç³»å’Œèƒ½é‡æµåŠ¨
3. ç»“åˆå’¨è¯¢è€…çš„ä¸ªäººç‰¹è´¨æä¾›é’ˆå¯¹æ€§å»ºè®®
4. è¯­è¨€å…·æœ‰å¯å‘æ€§å’Œæ´å¯ŸåŠ›ï¼Œä¸æµäºè¡¨é¢
5. è¿ç”¨ä¸­æ–‡çš„è¡¨è¾¾ä¼˜åŠ¿ï¼Œä½“ç°ä¸œæ–¹æ™ºæ…§ä¸è¥¿æ–¹å¡”ç½—çš„èåˆ

è¯·åŸºäºæä¾›çš„å‚è€ƒæ¡ˆä¾‹ï¼Œå­¦ä¹ å¹¶ä¿æŒè¿™ç§ä¸“ä¸šæ·±åº¦çš„è§£è¯»é£æ ¼ã€‚"""
        
        # æ„å»ºç”¨æˆ·æç¤º
        user_prompt = f"""è¯·ä¸ºä»¥ä¸‹å’¨è¯¢æä¾›ä¸“ä¸šå¡”ç½—è§£è¯»ï¼š

å’¨è¯¢è€…ï¼š{person}
é—®é¢˜ï¼š{question}
ç‰Œé˜µï¼š{spread}
æŠ½åˆ°çš„ç‰Œï¼š{' | '.join(cards)}

"""
        
        # æ·»åŠ å‚è€ƒæ¡ˆä¾‹ - ä¼˜åŒ–ç‰ˆ
        if similar_readings:
            user_prompt += "å‚è€ƒä½ ä»¥å¾€çš„è§£è¯»é£æ ¼å’Œæ¡ˆä¾‹ï¼š\n\n"
            
            # åˆ†ç±»å±•ç¤ºå‚è€ƒæ¡ˆä¾‹
            high_sim_readings = [r for r in similar_readings if r['similarity'] > 0.4]
            card_match_readings = [r for r in similar_readings if r['card_overlap'] > 0]
            same_person_readings = [r for r in similar_readings if r['person'] == person]
            
            case_count = 1
            
            # ä¼˜å…ˆæ˜¾ç¤ºé«˜ç›¸ä¼¼åº¦æ¡ˆä¾‹
            for reading in high_sim_readings[:2]:
                user_prompt += f"é«˜ç›¸ä¼¼åº¦å‚è€ƒ{case_count}ï¼š\n"
                user_prompt += f"å’¨è¯¢è€…: {reading['person']}\n"
                user_prompt += f"é—®é¢˜: {reading['question']}\n"
                user_prompt += f"ç‰Œç»„: {reading['cards']}\n"
                user_prompt += f"ç›¸ä¼¼åº¦: {reading['similarity']:.2f} (ç‰Œé‡å :{reading['card_overlap']}å¼ )\n"
                
                content = reading['content']
                if len(content) > 1000:
                    content = content[:1000] + "..."
                user_prompt += f"è§£è¯»é£æ ¼:\n{content}\n\n"
                case_count += 1
            
            # æ˜¾ç¤ºåŒç‰Œå‚è€ƒ
            for reading in card_match_readings[:2]:
                if reading not in high_sim_readings:
                    user_prompt += f"åŒç‰Œå‚è€ƒ{case_count}ï¼š\n"
                    user_prompt += f"å’¨è¯¢è€…: {reading['person']}\n"
                    user_prompt += f"é—®é¢˜: {reading['question']}\n"
                    user_prompt += f"ç‰Œç»„: {reading['cards']} (é‡å {reading['card_overlap']}å¼ )\n"
                    
                    content = reading['content']
                    if len(content) > 800:
                        content = content[:800] + "..."
                    user_prompt += f"è§£è¯»å‚è€ƒ:\n{content}\n\n"
                    case_count += 1
            
            # æ˜¾ç¤ºåŒäººå‚è€ƒ
            for reading in same_person_readings[:1]:
                if reading not in high_sim_readings and reading not in card_match_readings:
                    user_prompt += f"{person}çš„å†å²å‚è€ƒï¼š\n"
                    user_prompt += f"é—®é¢˜: {reading['question']}\n"
                    user_prompt += f"ç‰Œç»„: {reading['cards']}\n"
                    
                    content = reading['content']
                    if len(content) > 600:
                        content = content[:600] + "..."
                    user_prompt += f"ä¸ªäººç‰¹è´¨å‚è€ƒ:\n{content}\n\n"
        
        user_prompt += f"""åŸºäºä»¥ä¸Šå‚è€ƒé£æ ¼ï¼Œè¯·ä¸º{person}æä¾›æ·±åº¦ä¸“ä¸šçš„å¡”ç½—è§£è¯»ã€‚

è¦æ±‚ï¼š
1. é€ä¸€æ·±å…¥åˆ†ææŠ½åˆ°çš„æ¯å¼ ç‰Œï¼š{' | '.join(cards)}
2. æ¢è®¨ç‰Œç»„çš„æ•´ä½“ä¿¡æ¯å’Œèƒ½é‡æµå‘
3. ç»“åˆ{person}çš„ä¸ªäººç‰¹è´¨å’Œå½“å‰é—®é¢˜
4. æä¾›å…·ä½“çš„äººç”ŸæŒ‡å¯¼å»ºè®®
5. ä¿æŒæ·±åˆ»æ´å¯Ÿå’Œä¸“ä¸šæ°´å‡†
6. ä½“ç°ä¸­æ–‡è¡¨è¾¾çš„æ·±åº¦å’Œç¾æ„Ÿ

è¯·å¼€å§‹è§£è¯»ï¼š"""
        
        try:
            response = self.client.chat.completions.create(
                model="deepseek-reasoner",  # ä½¿ç”¨æ¨ç†æ¨¡å‹
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=2000,
                temperature=0.7,
                top_p=0.9
            )
            
            generated_content = response.choices[0].message.content
            
            # æ ¼å¼åŒ–æœ€ç»ˆè¾“å‡º
            final_reading = f"""ğŸ”® {person}çš„ä¸“ä¸šå¡”ç½—è§£è¯»

ğŸ“‹ å’¨è¯¢ä¿¡æ¯ï¼š
   é—®é¢˜ï¼š{question}
   ç‰Œé˜µï¼š{spread}
   æŠ½åˆ°çš„ç‰Œï¼š{' | '.join(cards)}

ğŸ¯ DeepSeek R1 æ·±åº¦è§£è¯»ï¼š
{generated_content}

 ğŸ“š å‚è€ƒä¿¡æ¯ï¼š
    é«˜ç›¸ä¼¼åº¦æ¡ˆä¾‹: {len([r for r in similar_readings if r['similarity'] > 0.4])} ä¸ª
    åŒç‰Œç»„æ¡ˆä¾‹: {len([r for r in similar_readings if r['card_overlap'] > 0])} ä¸ª
    åŒå’¨è¯¢è€…æ¡ˆä¾‹: {len([r for r in similar_readings if r['person'] == person])} ä¸ª
    ç”± DeepSeek R1 æ¨ç†æ¨¡å‹ç”Ÿæˆï¼Œç»“åˆäº†ä¼ ç»Ÿå¡”ç½—æ™ºæ…§ä¸ç°ä»£AIæ´å¯Ÿ

ğŸ’° æˆæœ¬ä¼˜åŠ¿ï¼š
   ç›¸æ¯”ä¼ ç»Ÿæ–¹æ¡ˆèŠ‚çœçº¦80%è´¹ç”¨ï¼ŒåŒæ—¶ä¿æŒä¸“ä¸šæ°´å‡†
"""
            
            return final_reading
            
        except Exception as e:
            return f"âŒ ç”Ÿæˆè§£è¯»æ—¶å‡ºé”™: {e}"
    
    def check_usage_and_cost(self):
        """æ£€æŸ¥ä½¿ç”¨æƒ…å†µå’Œæˆæœ¬"""
        try:
            # DeepSeekæš‚ä¸æä¾›ä½™é¢æŸ¥è¯¢APIï¼Œä½†å¯ä»¥ä¼°ç®—æˆæœ¬
            print("ğŸ’° DeepSeek R1 æˆæœ¬ä¼˜åŠ¿:")
            print("   - è¾“å…¥: $0.50/M tokens (vs OpenAI $10/M)")
            print("   - è¾“å‡º: $2.18/M tokens (vs OpenAI $30/M)")
            print("   - èŠ‚çœ: ~80%çš„è´¹ç”¨")
            print("   - æ¨ç†èƒ½åŠ›: æ¥è¿‘GPT-4æ°´å¹³")
            
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è·å–ä½¿ç”¨ä¿¡æ¯: {e}")

def main():
    print("ğŸ”® DeepSeek R1 + RAG å¡”ç½—AIç³»ç»Ÿ")
    print("="*50)
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    rag_ai = DeepSeekTarotRAG()
    
    if not rag_ai.client:
        print("âŒ DeepSeek åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥ API Key")
        return
    
    # æ˜¾ç¤ºæˆæœ¬ä¼˜åŠ¿
    rag_ai.check_usage_and_cost()
    
    # æ„å»ºçŸ¥è¯†åº“
    rag_ai.build_knowledge_base()
    
    # æµ‹è¯•æ¡ˆä¾‹
    print("\nğŸ§ª æµ‹è¯• DeepSeek R1 + RAG è§£è¯»...")
    
    test_cases = [
        {
            "person": "Mel",
            "question": "äº‹ä¸šå‘å±•æ–¹å‘",
            "cards": ["æ„šäºº(æ­£ä½)", "åŠ›é‡(æ­£ä½)", "æ˜Ÿå¸å(æ­£ä½)"],
            "spread": "ä¸‰å¼ ç‰Œè§£è¯»"
        },
        {
            "person": "æµ‹è¯•è€…",
            "question": "2024å¹´è¿åŠ¿",
            "cards": ["å¤ªé˜³(æ­£ä½)", "ä¸–ç•Œ(æ­£ä½)", "åœ£æ¯å(æ­£ä½)"],
            "spread": "å¹´åº¦ç‰Œé˜µ"
        }
    ]
    
    for i, case in enumerate(test_cases, 1):
        print(f"\n{'='*60}")
        print(f"æµ‹è¯•æ¡ˆä¾‹ {i}")
        print('='*60)
        
        reading = rag_ai.generate_reading(
            case["person"], case["question"], 
            case["cards"], case["spread"]
        )
        
        print(reading)
        
        if i < len(test_cases):
            input("\næŒ‰Enterç»§ç»­...")
    
    # äº¤äº’æ¨¡å¼
    print(f"\n{'='*60}")
    choice = input("æ˜¯å¦è¿›å…¥äº¤äº’æ¨¡å¼ï¼Ÿ(y/n): ").strip().lower()
    
    if choice in ['y', 'yes', 'æ˜¯']:
        print("\nğŸ¯ è¿›å…¥ DeepSeek R1 RAG äº¤äº’æ¨¡å¼ (è¾“å…¥ 'quit' é€€å‡º)")
        
        while True:
            try:
                print("\n" + "-"*40)
                person = input("å’¨è¯¢è€…å§“å: ").strip()
                if person.lower() == 'quit':
                    break
                
                question = input("é—®é¢˜: ").strip()
                if question.lower() == 'quit':
                    break
                
                cards_input = input("æŠ½åˆ°çš„ç‰Œ (ç”¨åˆ†å·;åˆ†éš”): ").strip()
                if cards_input.lower() == 'quit':
                    break
                
                cards = [card.strip() for card in cards_input.split(';') if card.strip()]
                
                spread = input("ç‰Œé˜µç±»å‹ (å¯é€‰): ").strip() or "è‡ªç”±ç‰Œé˜µ"
                if spread.lower() == 'quit':
                    break
                
                print("\nğŸ”® æ­£åœ¨ç”Ÿæˆ DeepSeek R1 è§£è¯»...")
                reading = rag_ai.generate_reading(person, question, cards, spread)
                
                print(f"\n{reading}")
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ DeepSeek R1 RAG å¡”ç½—AI!")
                break
            except Exception as e:
                print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
    
    print("\nğŸ‰ DeepSeek R1 RAG å¡”ç½—AI æµ‹è¯•å®Œæˆ!")
    print("ğŸ’¡ æ¨èï¼šDeepSeek R1 æä¾›äº†æ¥è¿‘GPT-4çš„èƒ½åŠ›ï¼Œä½†æˆæœ¬ä»…ä¸ºå…¶1/5")

if __name__ == "__main__":
    main() 