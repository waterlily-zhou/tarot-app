#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆRAGå¢å¼ºå¡”ç½—AIç³»ç»Ÿ - é¿å…å…¼å®¹æ€§é—®é¢˜
"""

import os
import sys
import torch
import json
import sqlite3
from pathlib import Path
from typing import List, Dict
import re

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"
os.environ["TOKENIZERS_PARALLELISM"] = "false"

try:
    from transformers import AutoTokenizer, AutoModelForCausalLM
    from peft import PeftModel
    print("âœ… æ ¸å¿ƒä¾èµ–åº“å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ ç¼ºå°‘ä¾èµ–åº“: {e}")
    sys.exit(1)

class SimpleTarotKnowledgeBase:
    """ç®€åŒ–çš„å¡”ç½—çŸ¥è¯†åº“ - åŸºäºå…³é”®è¯æ£€ç´¢"""
    
    def __init__(self, db_path: str = "data/simple_tarot_knowledge.db"):
        self.db_path = db_path
        self.init_database()
        
    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # åˆ›å»ºè¡¨æ ¼
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS readings (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                person TEXT,
                question TEXT,
                cards TEXT,
                spread TEXT,
                content TEXT,
                keywords TEXT,
                source_file TEXT
            )
        ''')
        
        conn.commit()
        conn.close()
        print(f"âœ… ç®€åŒ–çŸ¥è¯†åº“åˆå§‹åŒ–å®Œæˆ: {self.db_path}")
    
    def extract_keywords(self, text: str) -> str:
        """æå–å…³é”®è¯"""
        # ç®€å•çš„å…³é”®è¯æå–
        keywords = []
        
        # å¡”ç½—ç‰Œå
        tarot_cards = [
            "æ„šäºº", "é­”æœ¯å¸ˆ", "å¥³æ•™çš‡", "çš‡å", "çš‡å¸", "æ•™çš‡", "æ‹äºº", "æˆ˜è½¦", "åŠ›é‡", "éšå£«",
            "å‘½è¿ä¹‹è½®", "æ­£ä¹‰", "å€’åŠäºº", "æ­»ç¥", "èŠ‚åˆ¶", "æ¶é­”", "å¡”", "æ˜Ÿæ˜Ÿ", "æœˆäº®", "å¤ªé˜³",
            "å®¡åˆ¤", "ä¸–ç•Œ", "æƒæ–", "åœ£æ¯", "å®å‰‘", "æ˜Ÿå¸", "å›½ç‹", "çš‡å", "éª‘å£«", "ä¾è€…"
        ]
        
        # æƒ…æ„Ÿè¯æ±‡
        emotion_words = [
            "çˆ±æƒ…", "äº‹ä¸š", "è´¢è¿", "å¥åº·", "å­¦ä¹ ", "å®¶åº­", "å‹è°Š", "æˆé•¿", "æŒ‘æˆ˜", "æœºä¼š",
            "å›°éš¾", "æˆåŠŸ", "å¤±è´¥", "å¸Œæœ›", "ææƒ§", "å‹‡æ°”", "æ™ºæ…§", "ç›´è§‰", "å˜åŒ–", "ç¨³å®š"
        ]
        
        all_keywords = tarot_cards + emotion_words
        
        for keyword in all_keywords:
            if keyword in text:
                keywords.append(keyword)
        
        return ";".join(keywords)
    
    def add_reading(self, person: str, question: str, cards: List[str], 
                   spread: str, content: str, source_file: str):
        """æ·»åŠ è§£è¯»åˆ°çŸ¥è¯†åº“"""
        # æå–å…³é”®è¯
        full_text = f"{question} {' '.join(cards)} {content}"
        keywords = self.extract_keywords(full_text)
        
        # å­˜å‚¨åˆ°æ•°æ®åº“
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO readings (person, question, cards, spread, content, keywords, source_file)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        ''', (person, question, ';'.join(cards), spread, content, keywords, source_file))
        
        conn.commit()
        conn.close()
    
    def search_similar_readings(self, person: str, question: str, 
                              cards: List[str], spread: str, top_k: int = 3) -> List[Dict]:
        """æœç´¢ç›¸ä¼¼çš„è§£è¯»"""
        # ç”ŸæˆæŸ¥è¯¢å…³é”®è¯
        query_text = f"{question} {' '.join(cards)}"
        query_keywords = self.extract_keywords(query_text).split(";")
        
        # ä»æ•°æ®åº“æ£€ç´¢æ‰€æœ‰è®°å½•
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('SELECT * FROM readings')
        rows = cursor.fetchall()
        conn.close()
        
        if not rows:
            return []
        
        # è®¡ç®—å…³é”®è¯åŒ¹é…åº¦
        similarities = []
        for row in rows:
            stored_keywords = row[6].split(";") if row[6] else []
            
            # è®¡ç®—å…³é”®è¯é‡å 
            overlap = len(set(query_keywords) & set(stored_keywords))
            total_keywords = len(set(query_keywords) | set(stored_keywords))
            
            similarity = overlap / max(total_keywords, 1) if total_keywords > 0 else 0
            
            # å¦‚æœæ˜¯åŒä¸€ä¸ªäººï¼Œå¢åŠ æƒé‡
            if row[1] == person:
                similarity += 0.3
            
            similarities.append({
                'id': row[0],
                'person': row[1],
                'question': row[2],
                'cards': row[3],
                'spread': row[4],
                'content': row[5],
                'source_file': row[7],
                'similarity': similarity
            })
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        similarities.sort(key=lambda x: x['similarity'], reverse=True)
        
        return similarities[:top_k]

class SimpleRAGTarotAI:
    """ç®€åŒ–çš„RAGå¢å¼ºå¡”ç½—AI"""
    
    def __init__(self):
        self.knowledge_base = SimpleTarotKnowledgeBase()
        self.model = None
        self.tokenizer = None
        self.device = None
        
    def load_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        print("ğŸ¤– åŠ è½½ç®€åŒ–RAGå¡”ç½—AI...")
        
        # æ£€æŸ¥è®¾å¤‡
        if torch.backends.mps.is_available():
            self.device = "mps"
            print("âœ… ä½¿ç”¨ Apple Silicon MPS")
        else:
            self.device = "cpu"
            print("âš ï¸ ä½¿ç”¨ CPU")
        
        model_path = "./models/qwen-tarot-24gb"
        base_model_name = "Qwen/Qwen1.5-1.8B-Chat"
        
        if not Path(model_path).exists():
            print(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
            print("è¯·å…ˆè¿è¡Œæ¨¡å‹è®­ç»ƒ")
            return False
        
        try:
            # ä¿®å¤LoRAé…ç½®
            adapter_config_path = Path(model_path) / "adapter_config.json"
            if adapter_config_path.exists():
                with open(adapter_config_path, 'r') as f:
                    config = json.load(f)
                config["inference_mode"] = False
                with open(adapter_config_path, 'w') as f:
                    json.dump(config, f, indent=2)
            
            # åŠ è½½tokenizer
            self.tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
            
            # åŠ è½½base model
            print("ğŸ“¥ åŠ è½½åŸºç¡€æ¨¡å‹...")
            base_model = AutoModelForCausalLM.from_pretrained(
                base_model_name,
                torch_dtype=torch.float32,
                device_map="cpu",
                trust_remote_code=True,
                low_cpu_mem_usage=True
            )
            
            # åŠ è½½PEFT model
            print("ğŸ“¥ åŠ è½½å¾®è°ƒé€‚é…å™¨...")
            self.model = PeftModel.from_pretrained(base_model, model_path)
            
            # ç§»åŠ¨åˆ°è®¾å¤‡
            if self.device == "mps":
                print("ğŸ”„ ç§»åŠ¨åˆ°MPSè®¾å¤‡...")
                self.model = self.model.to("mps")
            
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("ğŸ’¡ å»ºè®®æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´")
            return False
    
    def build_knowledge_base(self):
        """æ„å»ºçŸ¥è¯†åº“"""
        print("ğŸ“š æ„å»ºç®€åŒ–å¡”ç½—çŸ¥è¯†åº“...")
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®
        conn = sqlite3.connect(self.knowledge_base.db_path)
        cursor = conn.cursor()
        cursor.execute('SELECT COUNT(*) FROM readings')
        count = cursor.fetchone()[0]
        conn.close()
        
        if count > 0:
            print(f"âœ… çŸ¥è¯†åº“å·²æœ‰ {count} æ¡è®°å½•")
            return
        
        # ä»è®­ç»ƒæ•°æ®æ„å»ºçŸ¥è¯†åº“
        data_file = "data/finetune/tarot_readings.jsonl"
        if not Path(data_file).exists():
            print(f"âŒ è®­ç»ƒæ•°æ®ä¸å­˜åœ¨: {data_file}")
            return
        
        count = 0
        print("ğŸ“„ æ­£åœ¨å¤„ç†è®­ç»ƒæ•°æ®...")
        
        with open(data_file, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    sample = json.loads(line)
                    metadata = sample['metadata']
                    
                    # æå–ä¿¡æ¯
                    person = metadata.get('person', '')
                    cards = metadata.get('cards', [])
                    spread = metadata.get('spread', '')
                    content = sample['response']
                    source_file = metadata.get('source_file', '')
                    
                    # ä»æŒ‡ä»¤ä¸­æå–é—®é¢˜
                    instruction = sample['instruction']
                    question_match = re.search(r'é—®é¢˜ï¼š([^\n]+)', instruction)
                    question = question_match.group(1) if question_match else ''
                    
                    # æ·»åŠ åˆ°çŸ¥è¯†åº“ (ä¿ç•™æ‰€æœ‰é«˜è´¨é‡çš„ä¸“ä¸šæ•°æ®)
                    self.knowledge_base.add_reading(
                        person, question, cards, spread, content, source_file
                    )
                    
                    count += 1
                    if count % 20 == 0:
                        print(f"   å·²å¤„ç† {count} æ¡è®°å½•...")
                        
                except Exception as e:
                    print(f"âš ï¸ å¤„ç†è®°å½•æ—¶å‡ºé”™: {e}")
        
        print(f"âœ… çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼Œå…± {count} æ¡è®°å½•")
    
    def generate_enhanced_reading(self, person: str, question: str, 
                                cards: List[str], spread: str = "è‡ªç”±ç‰Œé˜µ") -> str:
        """ç”ŸæˆRAGå¢å¼ºçš„è§£è¯»"""
        
        # 1. æ£€ç´¢ç›¸ä¼¼è§£è¯»
        print("ğŸ” æ£€ç´¢ç›¸ä¼¼è§£è¯»...")
        similar_readings = self.knowledge_base.search_similar_readings(
            person, question, cards, spread, top_k=3
        )
        
        # 2. æ„å»ºå¢å¼ºprompt
        enhanced_prompt = self._build_enhanced_prompt(
            person, question, cards, spread, similar_readings
        )
        
        # 3. ç”Ÿæˆè§£è¯»
        print("ğŸ¤– ç”Ÿæˆå¢å¼ºè§£è¯»...")
        generated = self._generate_with_model(enhanced_prompt)
        
        # 4. æ ¼å¼åŒ–æœ€ç»ˆç»“æœ
        final_reading = self._format_final_reading(
            person, question, cards, spread, generated, similar_readings
        )
        
        return final_reading
    
    def _build_enhanced_prompt(self, person: str, question: str, cards: List[str], 
                             spread: str, similar_readings: List[Dict]) -> str:
        """æ„å»ºå¢å¼ºprompt - ä¸“æ³¨ä½ çš„è§£è¯»é£æ ¼"""
        
        # æ„å»ºæ›´ä¸“ä¸šçš„promptï¼Œä½“ç°ä½ çš„è§£è¯»ç‰¹è‰²
        prompt = f"""ä¸“ä¸šå¡”ç½—è§£è¯»ä»»åŠ¡ï¼š

åŸºæœ¬ä¿¡æ¯ï¼š
- å’¨è¯¢è€…ï¼š{person}
- é—®é¢˜ï¼š{question}
- ç‰Œé˜µï¼š{spread}
- æŠ½åˆ°çš„ç‰Œï¼š{';'.join(cards)}

"""
        
        # æ·»åŠ æ›´å¤šä¸Šä¸‹æ–‡å‚è€ƒ
        if similar_readings:
            prompt += "å‚è€ƒä½ ä»¥å¾€çš„ä¸“ä¸šè§£è¯»é£æ ¼ï¼š\n\n"
            for i, reading in enumerate(similar_readings[:2], 1):  # åªç”¨å‰2ä¸ªæœ€ç›¸å…³çš„
                if reading['similarity'] > 0.05:
                    prompt += f"å‚è€ƒæ¡ˆä¾‹{i}ï¼š\n"
                    prompt += f"å’¨è¯¢è€…: {reading['person']}\n"
                    prompt += f"é—®é¢˜: {reading['question']}\n"
                    prompt += f"ç‰Œç»„: {reading['cards']}\n"
                    
                    # æå–è§£è¯»çš„æ ¸å¿ƒéƒ¨åˆ†ï¼ˆæ›´å¤šå†…å®¹ï¼‰
                    ref_content = reading['content']
                    # å–å‰800å­—ç¬¦ï¼Œä¿ç•™æ›´å¤šä¸“ä¸šå†…å®¹
                    if len(ref_content) > 800:
                        ref_content = ref_content[:800] + "..."
                    
                    prompt += f"è§£è¯»é£æ ¼å‚è€ƒ:\n{ref_content}\n\n"
        
        # æ›´æ˜ç¡®çš„æŒ‡ä»¤
        prompt += f"""è¯·åŸºäºä»¥ä¸Šå‚è€ƒï¼Œä¸º{person}æä¾›æ·±åº¦ä¸“ä¸šçš„å¡”ç½—è§£è¯»ã€‚
è¦æ±‚ï¼š
1. é’ˆå¯¹å…·ä½“æŠ½åˆ°çš„ç‰Œï¼š{';'.join(cards)}
2. ç»“åˆ{person}çš„ä¸ªäººèƒ½é‡ç‰¹è´¨
3. ä½“ç°ä¸“ä¸šçš„è§£è¯»æ·±åº¦å’Œæ´å¯ŸåŠ›
4. ä¿æŒä½ ä¸€è´¯çš„è§£è¯»é£æ ¼

å¼€å§‹è§£è¯»ï¼š"""
        
        return prompt
    
    def _generate_with_model(self, prompt: str) -> str:
        """ä½¿ç”¨æ¨¡å‹ç”Ÿæˆè§£è¯»"""
        try:
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦åŠ è½½æˆåŠŸ
            if self.model is None or self.tokenizer is None:
                return self._generate_simple_rule_based(prompt)
            
            inputs = self.tokenizer(prompt, return_tensors="pt", truncation=True, max_length=1200)
            if self.device == "mps":
                inputs = {k: v.to("mps") for k, v in inputs.items()}
            
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=300,
                    temperature=0.7,
                    do_sample=True,
                    pad_token_id=self.tokenizer.eos_token_id,
                    repetition_penalty=1.2,
                    top_p=0.8,
                    no_repeat_ngram_size=3
                )
            
            full_response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            generated = full_response[len(prompt):].strip()
            
            # åå¤„ç†ï¼šç¡®ä¿ç”Ÿæˆå†…å®¹ç¬¦åˆè¦æ±‚
            generated = self._post_process_generated(generated, prompt)
            
            return generated
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
            return self._generate_simple_rule_based(prompt)
    
    def _post_process_generated(self, generated: str, original_prompt: str) -> str:
        """åå¤„ç†ç”Ÿæˆçš„å†…å®¹"""
        # æå–æç¤ºä¸­çš„ç‰Œ
        import re
        prompt_cards = re.findall(r'ç‰Œï¼š([^\\n]+)', original_prompt)
        if prompt_cards:
            actual_cards = prompt_cards[0].split(';')
            
            # æ£€æŸ¥ç”Ÿæˆå†…å®¹æ˜¯å¦æåˆ°äº†æ­£ç¡®çš„ç‰Œ
            mentioned_correct_cards = any(card.strip() in generated for card in actual_cards)
            
            if not mentioned_correct_cards:
                # å¦‚æœæ²¡æœ‰æåˆ°æ­£ç¡®çš„ç‰Œï¼Œç”ŸæˆåŸºäºè§„åˆ™çš„è§£è¯»
                return self._generate_card_based_reading(actual_cards)
        
        # æ¸…ç†ç”Ÿæˆå†…å®¹
        if len(generated) < 50:
            return self._generate_simple_rule_based(original_prompt)
        
        # ç§»é™¤é‡å¤å†…å®¹
        lines = generated.split('\n')
        cleaned_lines = []
        seen_lines = set()
        
        for line in lines:
            line = line.strip()
            if line and line not in seen_lines:
                cleaned_lines.append(line)
                seen_lines.add(line)
        
        return '\n'.join(cleaned_lines)
    
    def _generate_card_based_reading(self, cards: List[str]) -> str:
        """åŸºäºå¡ç‰Œç”Ÿæˆç®€å•è§£è¯»"""
        card_meanings = {
            "æ„šäºº": {"æ­£ä½": "æ–°çš„å¼€å§‹ã€å†’é™©ç²¾ç¥ã€çº¯çœŸ", "é€†ä½": "é²è½ã€ç¼ºä¹è®¡åˆ’"},
            "åŠ›é‡": {"æ­£ä½": "å†…åœ¨åŠ›é‡ã€å‹‡æ°”ã€è€å¿ƒ", "é€†ä½": "è½¯å¼±ã€ç¼ºä¹è‡ªä¿¡"},
            "æ˜Ÿå¸å": {"æ­£ä½": "è´¢å¯Œåœ†æ»¡ã€å®¶åº­å’Œè°ã€ç‰©è´¨æˆåŠŸ", "é€†ä½": "è´¢åŠ¡æŸå¤±ã€å®¶åº­é—®é¢˜"},
            "åœ£æ¯äºŒ": {"æ­£ä½": "çˆ±æƒ…ã€ä¼™ä¼´å…³ç³»ã€å’Œè°", "é€†ä½": "å…³ç³»ç ´è£‚ã€ä¸å’Œ"},
            "åœ£æ¯å": {"æ­£ä½": "å®¶åº­å¹¸ç¦ã€æƒ…æ„Ÿæ»¡è¶³ã€å’Œè°", "é€†ä½": "å®¶åº­ä¸å’Œã€æƒ…æ„Ÿç©ºè™š"},
            "å®å‰‘ä¸ƒ": {"æ­£ä½": "ç­–ç•¥ã€æœºæ™ºã€ç‹¬ç«‹è¡ŒåŠ¨", "é€†ä½": "æ¬ºéª—ã€é€ƒé¿"},
            "æ‹äºº": {"æ­£ä½": "çˆ±æƒ…ã€é€‰æ‹©ã€å’Œè°å…³ç³»", "é€†ä½": "å…³ç³»é—®é¢˜ã€é”™è¯¯é€‰æ‹©"}
        }
        
        reading = "æ ¹æ®ä½ æŠ½åˆ°çš„ç‰Œï¼Œæˆ‘ä¸ºä½ è§£è¯»å¦‚ä¸‹ï¼š\n\n"
        
        for i, card in enumerate(cards, 1):
            card_name = card.replace("(æ­£ä½)", "").replace("(é€†ä½)", "").strip()
            position = "æ­£ä½" if "(æ­£ä½)" in card else "é€†ä½" if "(é€†ä½)" in card else "æ­£ä½"
            
            if card_name in card_meanings:
                meaning = card_meanings[card_name].get(position, "ä»£è¡¨ç€é‡è¦çš„äººç”Ÿè½¬æŠ˜")
                reading += f"{i}. **{card}**: {meaning}ã€‚"
            else:
                reading += f"{i}. **{card}**: è¿™å¼ ç‰Œæé†’ä½ å…³æ³¨å†…å¿ƒçš„å£°éŸ³å’Œç›´è§‰ã€‚"
            
            reading += "\n"
        
        reading += "\næ•´ä½“è€Œè¨€ï¼Œè¿™æ¬¡æŠ½ç‰Œæ˜¾ç¤ºäº†ä½ å½“å‰ç”Ÿæ´»ä¸­çš„é‡è¦è®®é¢˜ã€‚å»ºè®®ä½ ä¿æŒå¼€æ”¾çš„å¿ƒæ€ï¼Œç›¸ä¿¡è‡ªå·±çš„ç›´è§‰ï¼Œåœ¨é¢å¯¹é€‰æ‹©æ—¶è¦è°¨æ…è€ƒè™‘ã€‚"
        
        return reading
    
    def _generate_simple_rule_based(self, prompt: str) -> str:
        """ç®€å•çš„åŸºäºè§„åˆ™çš„ç”Ÿæˆ"""
        return "ç”±äºæŠ€æœ¯é™åˆ¶ï¼Œæš‚æ—¶æ— æ³•ç”Ÿæˆè¯¦ç»†è§£è¯»ã€‚å»ºè®®ä½ é‡æ–°æŠ½ç‰Œæˆ–è”ç³»ä¸“ä¸šå¡”ç½—å¸ˆè¿›è¡Œè§£è¯»ã€‚"
    
    def _is_good_quality_data(self, question: str, cards: List[str], content: str) -> bool:
        """æ£€æŸ¥æ•°æ®è´¨é‡"""
        # è¿‡æ»¤åŒ…å«HTMLæ ‡ç­¾æˆ–å›¾ç‰‡è¯†åˆ«é”™è¯¯çš„æ•°æ®
        if '<!--' in question or '<' in question or 'Card 1:' in question:
            return False
        
        # è¿‡æ»¤é—®é¢˜ä¸ºç©ºæˆ–è¿‡çŸ­çš„æ•°æ®
        if not question or len(question.strip()) < 3:
            return False
        
        # è¿‡æ»¤å¡ç‰Œä¿¡æ¯å¼‚å¸¸çš„æ•°æ®
        if not cards or len(cards) == 0:
            return False
        
        # è¿‡æ»¤å†…å®¹è¿‡çŸ­çš„æ•°æ®
        if not content or len(content.strip()) < 100:
            return False
        
        # è¿‡æ»¤åŒ…å«è¿‡å¤šä¸“ä¸šæœ¯è¯­çš„æ•°æ®ï¼ˆè¿™äº›å¯¹æ¨¡å‹å­¦ä¹ æ²¡æœ‰å¸®åŠ©ï¼‰
        complex_terms_count = sum(1 for term in [
            'æ˜Ÿå®¿', 'å®«ä½', 'æµ·ç‹æ˜Ÿ', 'å¤©åº•', 'åŒ—æ', 'å—å¤©é“¶æ²³', 'æ’æ˜Ÿ',
            'æˆ¿å®¿', 'å¿ƒå®¿', 'å®¤å®¿', 'å¥‡æ•°å®«', 'å¶æ•°å®«', 'æ‹±å‘', 'åˆ‘å…‹'
        ] if term in content)
        
        if complex_terms_count > 5:  # å¦‚æœä¸“ä¸šæœ¯è¯­è¿‡å¤šï¼Œè·³è¿‡
            return False
        
        return True
    
    def _format_final_reading(self, person: str, question: str, cards: List[str], 
                            spread: str, generated: str, similar_readings: List[Dict]) -> str:
        """æ ¼å¼åŒ–æœ€ç»ˆè§£è¯»"""
        
        final_reading = f"""ğŸ”® {person}çš„å¡”ç½—è§£è¯»

ğŸ“‹ å’¨è¯¢ä¿¡æ¯ï¼š
   é—®é¢˜ï¼š{question}
   ç‰Œé˜µï¼š{spread}
   æŠ½åˆ°çš„ç‰Œï¼š{' | '.join(cards)}

ğŸ¯ AIè§£è¯»ï¼š
{generated}

"""
        
        # æ·»åŠ å‚è€ƒä¿¡æ¯
        if similar_readings:
            high_sim_refs = [r for r in similar_readings if r['similarity'] > 0.2]
            if high_sim_refs:
                final_reading += "ğŸ“š ç›¸å…³å‚è€ƒï¼š\n"
                for i, reading in enumerate(high_sim_refs[:2], 1):
                    final_reading += f"   å‚è€ƒ{i}: {reading['person']}çš„{reading['question']} (åŒ¹é…åº¦: {reading['similarity']:.1%})\n"
        
        return final_reading

def main():
    print("ğŸ”® ç®€åŒ–ç‰ˆRAGå¢å¼ºå¡”ç½—AIç³»ç»Ÿ")
    print("="*50)
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    rag_ai = SimpleRAGTarotAI()
    
    # åŠ è½½æ¨¡å‹
    if not rag_ai.load_model():
        print("âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå°†ä½¿ç”¨çº¯æ£€ç´¢æ¨¡å¼")
        return
    
    # æ„å»ºçŸ¥è¯†åº“
    rag_ai.build_knowledge_base()
    
    # æµ‹è¯•æ¡ˆä¾‹
    print("\nğŸ§ª æµ‹è¯•ç®€åŒ–RAGè§£è¯»...")
    
    test_cases = [
        {
            "person": "Mel",
            "question": "äº‹ä¸šå‘å±•æ–¹å‘",
            "cards": ["æ„šäºº(æ­£ä½)", "åŠ›é‡(æ­£ä½)", "æ˜Ÿå¸å(æ­£ä½)"],
            "spread": "ä¸‰å¼ ç‰Œè§£è¯»"
        }
    ]
    
    for i, case in enumerate(test_cases, 1):
        print(f"\n{'='*60}")
        print(f"æµ‹è¯•æ¡ˆä¾‹ {i}")
        print('='*60)
        
        reading = rag_ai.generate_enhanced_reading(
            case["person"], case["question"], 
            case["cards"], case["spread"]
        )
        
        print(reading)
    
    # äº¤äº’æ¨¡å¼
    print(f"\n{'='*60}")
    choice = input("æ˜¯å¦è¿›å…¥äº¤äº’æ¨¡å¼ï¼Ÿ(y/n): ").strip().lower()
    
    if choice in ['y', 'yes', 'æ˜¯']:
        print("\nğŸ¯ è¿›å…¥ç®€åŒ–RAGäº¤äº’æ¨¡å¼ (è¾“å…¥ 'quit' é€€å‡º)")
        
        while True:
            try:
                print("\n" + "-"*40)
                person = input("å’¨è¯¢è€…å§“å: ").strip()
                if person.lower() == 'quit':
                    break
                
                question = input("é—®é¢˜: ").strip()
                if question.lower() == 'quit':
                    break
                
                cards_input = input("æŠ½åˆ°çš„ç‰Œ (ç”¨åˆ†å·;åˆ†éš”): ").strip()
                if cards_input.lower() == 'quit':
                    break
                
                cards = [card.strip() for card in cards_input.split(';') if card.strip()]
                
                spread = input("ç‰Œé˜µç±»å‹ (å¯é€‰): ").strip() or "è‡ªç”±ç‰Œé˜µ"
                if spread.lower() == 'quit':
                    break
                
                print("\nğŸ”® æ­£åœ¨ç”Ÿæˆç®€åŒ–RAGè§£è¯»...")
                reading = rag_ai.generate_enhanced_reading(person, question, cards, spread)
                
                print(f"\n{reading}")
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ç®€åŒ–RAGå¡”ç½—AI!")
                break
            except Exception as e:
                print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
    
    print("\nğŸ‰ ç®€åŒ–RAGå¡”ç½—AIç³»ç»Ÿæµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    main() 